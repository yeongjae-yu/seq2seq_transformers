{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0147,  0.5510,  1.2563],\n",
      "        [-0.6739, -1.0578, -0.7639],\n",
      "        [ 0.3787, -0.4891,  1.1139],\n",
      "        [ 1.1028, -0.9469, -1.3231],\n",
      "        [-0.0905,  0.0940, -0.3365]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 1])\n",
      "tensor([[[ 1.0147],\n",
      "         [ 0.5510],\n",
      "         [ 1.2563]],\n",
      "\n",
      "        [[-0.6739],\n",
      "         [-1.0578],\n",
      "         [-0.7639]],\n",
      "\n",
      "        [[ 0.3787],\n",
      "         [-0.4891],\n",
      "         [ 1.1139]],\n",
      "\n",
      "        [[ 1.1028],\n",
      "         [-0.9469],\n",
      "         [-1.3231]],\n",
      "\n",
      "        [[-0.0905],\n",
      "         [ 0.0940],\n",
      "         [-0.3365]]])\n"
     ]
    }
   ],
   "source": [
    "print(x.unsqueeze(-1).size())\n",
    "print(x.unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 3])\n",
      "tensor([[[ 1.0147,  0.5510,  1.2563],\n",
      "         [-0.6739, -1.0578, -0.7639],\n",
      "         [ 0.3787, -0.4891,  1.1139],\n",
      "         [ 1.1028, -0.9469, -1.3231],\n",
      "         [-0.0905,  0.0940, -0.3365]]])\n"
     ]
    }
   ],
   "source": [
    "print(x.unsqueeze(0).size())\n",
    "print(x.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.randn(6, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 5])\n",
      "tensor([[0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "y = x.unsqueeze(0).expand_as(input_ids)\n",
    "print(y.size())\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3160,  1.0719,  3.2948,  3.5629,  5.0383],\n",
       "        [-0.5004,  2.2755,  1.5341,  3.1248,  5.0559],\n",
       "        [-1.7600,  1.7466,  2.6826,  2.1746,  4.7072],\n",
       "        [ 0.4642,  1.8645,  0.9007,  3.8681,  4.3930],\n",
       "        [-0.2154,  0.5208,  2.7829,  3.2703,  4.5508],\n",
       "        [-0.2529,  1.6966,  2.1995,  4.2893,  4.5484]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "token_type_ids = torch.zeros_like(input_ids)\n",
    "print(token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word torch.Size([5, 6])\n"
     ]
    }
   ],
   "source": [
    "word_embeddings = nn.Embedding(5, 6, padding_idx=0)\n",
    "print('word', word_embeddings.weight.size())\n",
    "position_embeddings = nn.Embedding(6, 6)\n",
    "token_type_embdeeings = nn.Embedding(5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.4579,  1.0892, -0.3312, -0.2074, -0.4237,  0.9147],\n",
       "        [ 0.3414, -1.5100,  0.0070,  1.5652,  0.0486,  1.8483],\n",
       "        [-0.1010, -1.2528, -0.2252, -0.0108,  0.2299,  0.1938],\n",
       "        [-0.6949, -0.8128, -1.5756,  0.8243, -0.0091,  0.6609]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(word_embeddings.weight.size())\n",
    "word_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.4579,  1.0892, -0.3312, -0.2074, -0.4237,  0.9147],\n",
       "        [ 0.3414, -1.5100,  0.0070,  1.5652,  0.0486,  1.8483],\n",
       "        [-0.1010, -1.2528, -0.2252, -0.0108,  0.2299,  0.1938],\n",
       "        [-0.6949, -0.8128, -1.5756,  0.8243, -0.0091,  0.6609]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(word_embeddings(torch.arange(5)).size())\n",
    "word_embeddings(torch.arange(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "torch.Size([5, 1, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.4579,  1.0892, -0.3312, -0.2074, -0.4237,  0.9147]],\n",
       "\n",
       "        [[ 0.3414, -1.5100,  0.0070,  1.5652,  0.0486,  1.8483]],\n",
       "\n",
       "        [[-0.1010, -1.2528, -0.2252, -0.0108,  0.2299,  0.1938]],\n",
       "\n",
       "        [[-0.6949, -0.8128, -1.5756,  0.8243, -0.0091,  0.6609]]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.arange(5).view(5, -1))\n",
    "print(word_embeddings(torch.arange(5).view(5, -1)).size())\n",
    "word_embeddings(torch.arange(5).view(5, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0524,  0.4486,  0.7723, -0.5151,  0.5046,  0.1918],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings(torch.tensor(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "input1 = torch.ones(3, 2, dtype=torch.float)\n",
    "print(input1.size())\n",
    "print(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "tensor([[-0.2503, -0.3038, -0.3790],\n",
      "        [-0.4319, -0.7004, -0.4276]], grad_fn=<PermuteBackward>)\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(2, 3, bias=False)\n",
    "print(layer1.weight.size())\n",
    "print(layer1.weight.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "tensor([[-0.6822, -1.0042, -0.8066],\n",
      "        [-0.6822, -1.0042, -0.8066],\n",
      "        [-0.6822, -1.0042, -0.8066]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "output1 = layer1(input1)\n",
    "print(output1.size())\n",
    "print(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6822, -1.0042, -0.8066],\n",
      "        [-0.6822, -1.0042, -0.8066],\n",
      "        [-0.6822, -1.0042, -0.8066]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.6822, -0.6822, -0.6822],\n",
      "        [-1.0042, -1.0042, -1.0042],\n",
      "        [-0.8066, -0.8066, -0.8066]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "tmp_layer1 = layer1.weight\n",
    "print(input1.matmul(tmp_layer1.T))\n",
    "print(tmp_layer1.matmul(input1.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2503, -0.4319],\n",
       "        [-0.3038, -0.7004],\n",
       "        [-0.3790, -0.4276]], requires_grad=True)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128, 768])\n",
      "torch.Size([32, 128, 12, 64])\n",
      "torch.Size([32, 128, 12, 64])\n",
      "torch.Size([32, 128, 12, 64])\n",
      "torch.Size([32, 128, 12, 64])\n",
      "torch.Size([32, 12, 128, 64])\n",
      "torch.Size([32, 12, 128, 64])\n",
      "torch.Size([32, 12, 128, 64])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.randn([32, 128, 768])\n",
    "print(t1.size())\n",
    "new_shape = t1.size()[:-1] + (12, 64)\n",
    "print(new_shape)\n",
    "q = t1.view(new_shape)\n",
    "print(q.size())\n",
    "k = t1.view(*new_shape)\n",
    "print(k.size())\n",
    "v = t1.view(*new_shape)\n",
    "print(v.size())\n",
    "q = q.permute(0, 2, 1, 3)\n",
    "print(q.size())\n",
    "k = k.permute(0, 2, 1, 3)\n",
    "print(k.size())\n",
    "v = v.permute(0, 2, 1, 3)\n",
    "print(v.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 12, 64, 128])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.transpose(-1, -2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 12, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "a = torch.matmul(q, k.transpose(-1, -2))\n",
    "print(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 12, 128, 64])\n"
     ]
    }
   ],
   "source": [
    "result = torch.matmul(a, v)\n",
    "print(result.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128, 12, 64])\n",
      "torch.Size([32, 128, 768])\n"
     ]
    }
   ],
   "source": [
    "c = result.permute(0, 2, 1, 3).contiguous()\n",
    "print(c.size())\n",
    "new_c_shape = c.size()[:-2] + (768,)\n",
    "c = c.view(new_c_shape)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128, 12, 64])\n",
      "torch.Size([32, 128, 768])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-5bd34df7af1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnew_c_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m768\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_c_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_c_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "c = result.permute(0, 2, 1, 3)\n",
    "print(c.size())\n",
    "new_c_shape = c.size()[:-2] + (768,)\n",
    "print(new_c_shape)\n",
    "c = c.view(new_c_shape)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### attention head size 만큼 왜 먼저 나누지 않고 matmul 하고 split 했는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 128])\n",
      "torch.Size([128, 128])\n"
     ]
    }
   ],
   "source": [
    "# ex1 \n",
    "batch_size = 1\n",
    "seq_length = 1\n",
    "hidden_size = 128\n",
    "num_heads = 8\n",
    "head_size = int(hidden_size / num_heads)\n",
    "all_head_size = num_heads * head_size\n",
    "\n",
    "hidden_states = torch.randn(batch_size, seq_length, hidden_size)\n",
    "print(hidden_states.size())\n",
    "\n",
    "w_query = nn.Linear(hidden_size, all_head_size)\n",
    "w_key = nn.Linear(hidden_size, all_head_size)\n",
    "w_vlaue = nn.Linear(hidden_size, all_head_size)\n",
    "print(w_query.weight.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 128])\n"
     ]
    }
   ],
   "source": [
    "query = w_query(hidden_states)\n",
    "print(query.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각종 mask 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[3091, 3604,  206, 3958, 3760, 3590,    0,    0],\n",
    "                       [ 212, 3605,   53, 3832, 3596, 3682, 3760, 3590]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_pad_mask(seq_q, seq_k):\n",
    "    # print(seq_q)\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    # eq(zero) is PAD token\n",
    "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # batch_size x 1 x len_k(=len_q), one is masking\n",
    "    return pad_attn_mask.expand(batch_size, len_q, len_k)  # batch_size x len_q x len_k\n",
    "\n",
    "def transpose_for_attention_scores(x):\n",
    "    new_x_shape = x.size()[:-1] + (num_heads, head_size)\n",
    "    x = x.view(new_x_shape)\n",
    "    return x.permute(0, 2, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 8])\n",
      "torch.Size([2, 8, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "attention_mask = get_attn_pad_mask(inputs, inputs)\n",
    "print(attention_mask.size())\n",
    "attention_mask = attention_mask.unsqueeze(1).repeat(1, num_heads, 1, 1)\n",
    "print(attention_mask.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 8])\n",
      "tensor([[False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True]])\n"
     ]
    }
   ],
   "source": [
    "attn_mask2 = inputs.eq(0).unsqueeze(1).repeat(1, inputs.size()[1], 1)\n",
    "print(attn_mask2.size())\n",
    "print(attn_mask2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True]])\n"
     ]
    }
   ],
   "source": [
    "print(attention_mask[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = nn.Embedding(5000, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 128])\n",
      "torch.Size([2, 8, 8, 16])\n",
      "torch.Size([2, 8, 8, 8])\n",
      "tensor([[ 4.6761,  0.0964, -0.8392,  1.0350,  0.6139, -0.7481,  1.7292,  1.7292],\n",
      "        [ 0.0964,  5.7820, -0.2166,  0.5408,  0.4307, -0.2465,  1.4741,  1.4741],\n",
      "        [-0.8392, -0.2166,  5.6125, -0.5546, -0.5507, -0.0594,  0.7508,  0.7508],\n",
      "        [ 1.0350,  0.5408, -0.5546,  4.2115,  0.0281,  0.6837, -0.0087, -0.0087],\n",
      "        [ 0.6139,  0.4307, -0.5507,  0.0281,  6.2815,  0.3990, -0.3775, -0.3775],\n",
      "        [-0.7481, -0.2465, -0.0594,  0.6837,  0.3990,  2.5180, -0.5743, -0.5743],\n",
      "        [ 1.7292,  1.4741,  0.7508, -0.0087, -0.3775, -0.5743,  3.4868,  3.4868],\n",
      "        [ 1.7292,  1.4741,  0.7508, -0.0087, -0.3775, -0.5743,  3.4868,  3.4868]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[ 4.6761e+00,  9.6396e-02, -8.3923e-01,  1.0350e+00,  6.1386e-01,\n",
      "         -7.4811e-01, -1.0000e+09, -1.0000e+09],\n",
      "        [ 9.6396e-02,  5.7820e+00, -2.1659e-01,  5.4077e-01,  4.3070e-01,\n",
      "         -2.4650e-01, -1.0000e+09, -1.0000e+09],\n",
      "        [-8.3923e-01, -2.1659e-01,  5.6125e+00, -5.5461e-01, -5.5071e-01,\n",
      "         -5.9364e-02, -1.0000e+09, -1.0000e+09],\n",
      "        [ 1.0350e+00,  5.4077e-01, -5.5461e-01,  4.2115e+00,  2.8108e-02,\n",
      "          6.8371e-01, -1.0000e+09, -1.0000e+09],\n",
      "        [ 6.1386e-01,  4.3070e-01, -5.5071e-01,  2.8108e-02,  6.2815e+00,\n",
      "          3.9900e-01, -1.0000e+09, -1.0000e+09],\n",
      "        [-7.4811e-01, -2.4650e-01, -5.9364e-02,  6.8371e-01,  3.9900e-01,\n",
      "          2.5180e+00, -1.0000e+09, -1.0000e+09],\n",
      "        [ 1.7292e+00,  1.4741e+00,  7.5080e-01, -8.7306e-03, -3.7750e-01,\n",
      "         -5.7430e-01, -1.0000e+09, -1.0000e+09],\n",
      "        [ 1.7292e+00,  1.4741e+00,  7.5080e-01, -8.7306e-03, -3.7750e-01,\n",
      "         -5.7430e-01, -1.0000e+09, -1.0000e+09]], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "enc_inputs = word_embeddings(inputs)\n",
    "print(enc_inputs.size())\n",
    "q = transpose_for_attention_scores(enc_inputs)\n",
    "k = transpose_for_attention_scores(enc_inputs)\n",
    "v = transpose_for_attention_scores(enc_inputs)\n",
    "print(q.size())\n",
    "scores = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(head_size)\n",
    "print(scores.size())\n",
    "print(scores[0][0])\n",
    "scores.masked_fill_(attention_mask, -1e9)\n",
    "print(scores[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n",
      "torch.Size([2, 8])\n",
      "tensor([[False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False]])\n",
      "torch.Size([2, 8])\n",
      "tensor([[1, 2, 3, 4, 5, 6, 0, 0],\n",
      "        [1, 2, 3, 4, 5, 6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "position_ids = torch.arange(inputs.size()[1], dtype=torch.long, device=inputs.device)\n",
    "print(position_ids)\n",
    "position_ids = position_ids.unsqueeze(0).expand_as(inputs) + 1\n",
    "position_mask = inputs.eq(0)\n",
    "print(position_mask.size())\n",
    "print(position_mask)\n",
    "position_ids.masked_fill_(position_mask, 0)\n",
    "print(position_ids.size())\n",
    "print(position_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.functional.relu vs nn.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3091, 3604,  206, 3958, 3760, 3590,    0,    0],\n",
       "        [ 212, 3605,   53, 3832, 3596, 3682, 3760, 3590]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu1 = nn.functional.relu\n",
    "relu2 = nn.ReLU()\n",
    "relu2(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
