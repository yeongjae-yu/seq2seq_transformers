{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 행렬 요소 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8374, -1.2301, -0.7227],\n",
      "        [-0.8427, -0.1762, -0.4047],\n",
      "        [-0.0641,  0.3220,  1.1210],\n",
      "        [ 0.2619, -0.2958,  2.6746],\n",
      "        [ 0.7297, -0.1729, -0.3651]])\n",
      "tensor([[ 0.1626, -0.2301,  0.2773],\n",
      "        [ 0.1573,  0.8238,  0.5953],\n",
      "        [ 0.9359,  1.3220,  2.1210],\n",
      "        [ 1.2619,  0.7042,  3.6746],\n",
      "        [ 1.7297,  0.8271,  0.6349]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5, 3)\n",
    "print(x)\n",
    "print(x+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unsqueeze, squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 1])\n",
      "tensor([[[ 1.0147],\n",
      "         [ 0.5510],\n",
      "         [ 1.2563]],\n",
      "\n",
      "        [[-0.6739],\n",
      "         [-1.0578],\n",
      "         [-0.7639]],\n",
      "\n",
      "        [[ 0.3787],\n",
      "         [-0.4891],\n",
      "         [ 1.1139]],\n",
      "\n",
      "        [[ 1.1028],\n",
      "         [-0.9469],\n",
      "         [-1.3231]],\n",
      "\n",
      "        [[-0.0905],\n",
      "         [ 0.0940],\n",
      "         [-0.3365]]])\n"
     ]
    }
   ],
   "source": [
    "print(x.unsqueeze(-1).size())\n",
    "print(x.unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 3])\n",
      "tensor([[[ 1.0147,  0.5510,  1.2563],\n",
      "         [-0.6739, -1.0578, -0.7639],\n",
      "         [ 0.3787, -0.4891,  1.1139],\n",
      "         [ 1.1028, -0.9469, -1.3231],\n",
      "         [-0.0905,  0.0940, -0.3365]]])\n"
     ]
    }
   ],
   "source": [
    "print(x.unsqueeze(0).size())\n",
    "print(x.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.randn(6, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expand_as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 5])\n",
      "tensor([[0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "y = x.unsqueeze(0).expand_as(input_ids)\n",
    "print(y.size())\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3160,  1.0719,  3.2948,  3.5629,  5.0383],\n",
       "        [-0.5004,  2.2755,  1.5341,  3.1248,  5.0559],\n",
       "        [-1.7600,  1.7466,  2.6826,  2.1746,  4.7072],\n",
       "        [ 0.4642,  1.8645,  0.9007,  3.8681,  4.3930],\n",
       "        [-0.2154,  0.5208,  2.7829,  3.2703,  4.5508],\n",
       "        [-0.2529,  1.6966,  2.1995,  4.2893,  4.5484]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "token_type_ids = torch.zeros_like(input_ids)\n",
    "print(token_type_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word torch.Size([5, 6])\n"
     ]
    }
   ],
   "source": [
    "word_embeddings = nn.Embedding(5, 6, padding_idx=0)\n",
    "print('word', word_embeddings.weight.size())\n",
    "position_embeddings = nn.Embedding(6, 6)\n",
    "token_type_embdeeings = nn.Embedding(5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.4579,  1.0892, -0.3312, -0.2074, -0.4237,  0.9147],\n",
       "        [ 0.3414, -1.5100,  0.0070,  1.5652,  0.0486,  1.8483],\n",
       "        [-0.1010, -1.2528, -0.2252, -0.0108,  0.2299,  0.1938],\n",
       "        [-0.6949, -0.8128, -1.5756,  0.8243, -0.0091,  0.6609]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(word_embeddings.weight.size())\n",
    "word_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.4579,  1.0892, -0.3312, -0.2074, -0.4237,  0.9147],\n",
       "        [ 0.3414, -1.5100,  0.0070,  1.5652,  0.0486,  1.8483],\n",
       "        [-0.1010, -1.2528, -0.2252, -0.0108,  0.2299,  0.1938],\n",
       "        [-0.6949, -0.8128, -1.5756,  0.8243, -0.0091,  0.6609]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(word_embeddings(torch.arange(5)).size())\n",
    "word_embeddings(torch.arange(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "torch.Size([5, 1, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.4579,  1.0892, -0.3312, -0.2074, -0.4237,  0.9147]],\n",
       "\n",
       "        [[ 0.3414, -1.5100,  0.0070,  1.5652,  0.0486,  1.8483]],\n",
       "\n",
       "        [[-0.1010, -1.2528, -0.2252, -0.0108,  0.2299,  0.1938]],\n",
       "\n",
       "        [[-0.6949, -0.8128, -1.5756,  0.8243, -0.0091,  0.6609]]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.arange(5).view(5, -1))\n",
    "print(word_embeddings(torch.arange(5).view(5, -1)).size())\n",
    "word_embeddings(torch.arange(5).view(5, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0524,  0.4486,  0.7723, -0.5151,  0.5046,  0.1918],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings(torch.tensor(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Linear 연산 low level 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "input1 = torch.ones(3, 2, dtype=torch.float)\n",
    "print(input1.size())\n",
    "print(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "tensor([[-0.2503, -0.3038, -0.3790],\n",
      "        [-0.4319, -0.7004, -0.4276]], grad_fn=<PermuteBackward>)\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(2, 3, bias=False)\n",
    "print(layer1.weight.size())\n",
    "print(layer1.weight.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "tensor([[-0.6822, -1.0042, -0.8066],\n",
      "        [-0.6822, -1.0042, -0.8066],\n",
      "        [-0.6822, -1.0042, -0.8066]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "output1 = layer1(input1)\n",
    "print(output1.size())\n",
    "print(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6822, -1.0042, -0.8066],\n",
      "        [-0.6822, -1.0042, -0.8066],\n",
      "        [-0.6822, -1.0042, -0.8066]], grad_fn=<MmBackward>)\n",
      "tensor([[-0.6822, -0.6822, -0.6822],\n",
      "        [-1.0042, -1.0042, -1.0042],\n",
      "        [-0.8066, -0.8066, -0.8066]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "tmp_layer1 = layer1.weight\n",
    "print(input1.matmul(tmp_layer1.T)) # input * layer 연산처럼 계산이 된다\n",
    "print(tmp_layer1.matmul(input1.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2503, -0.4319],\n",
       "        [-0.3038, -0.7004],\n",
       "        [-0.3790, -0.4276]], requires_grad=True)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multihead attention 연산 및 contiguous 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128, 768])\n",
      "torch.Size([32, 128, 12, 64])\n",
      "torch.Size([32, 128, 12, 64])\n",
      "torch.Size([32, 128, 12, 64])\n",
      "torch.Size([32, 128, 12, 64])\n",
      "torch.Size([32, 12, 128, 64])\n",
      "torch.Size([32, 12, 128, 64])\n",
      "torch.Size([32, 12, 128, 64])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.randn([32, 128, 768])\n",
    "print(t1.size())\n",
    "new_shape = t1.size()[:-1] + (12, 64)\n",
    "print(new_shape)\n",
    "q = t1.view(new_shape)\n",
    "print(q.size())\n",
    "k = t1.view(*new_shape)\n",
    "print(k.size())\n",
    "v = t1.view(*new_shape)\n",
    "print(v.size())\n",
    "q = q.permute(0, 2, 1, 3)\n",
    "print(q.size())\n",
    "k = k.permute(0, 2, 1, 3)\n",
    "print(k.size())\n",
    "v = v.permute(0, 2, 1, 3)\n",
    "print(v.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 12, 64, 128])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.transpose(-1, -2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 12, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "a = torch.matmul(q, k.transpose(-1, -2))\n",
    "print(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 12, 128, 64])\n"
     ]
    }
   ],
   "source": [
    "result = torch.matmul(a, v)\n",
    "print(result.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128, 12, 64])\n",
      "torch.Size([32, 128, 768])\n"
     ]
    }
   ],
   "source": [
    "c = result.permute(0, 2, 1, 3).contiguous()\n",
    "print(c.size())\n",
    "new_c_shape = c.size()[:-2] + (768,)\n",
    "c = c.view(new_c_shape)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128, 12, 64])\n",
      "torch.Size([32, 128, 768])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-5bd34df7af1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnew_c_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m768\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_c_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_c_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "# permute 연산을 할 때는 반드시 contiguous() 이용하자\n",
    "c = result.permute(0, 2, 1, 3)\n",
    "print(c.size())\n",
    "new_c_shape = c.size()[:-2] + (768,)\n",
    "print(new_c_shape)\n",
    "c = c.view(new_c_shape)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### attention head size 만큼 왜 먼저 나누지 않고 matmul 하고 split 했는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 128])\n",
      "torch.Size([128, 128])\n"
     ]
    }
   ],
   "source": [
    "# 테크닉적 관점에서 유리 > 연산량을 줄이기 위해 matmul 하고 split \n",
    "# 결국 잘라진 head_size 만큼을 열에 이어 붙여(concat) 웨이트 계산을 하므로 서로 다른 head_size 가 연관되지 않을 수 있다\n",
    "batch_size = 1\n",
    "seq_length = 1\n",
    "hidden_size = 128\n",
    "num_heads = 8\n",
    "head_size = int(hidden_size / num_heads)\n",
    "all_head_size = num_heads * head_size\n",
    "\n",
    "hidden_states = torch.randn(batch_size, seq_length, hidden_size)\n",
    "print(hidden_states.size())\n",
    "\n",
    "w_query = nn.Linear(hidden_size, all_head_size)\n",
    "w_key = nn.Linear(hidden_size, all_head_size)\n",
    "w_vlaue = nn.Linear(hidden_size, all_head_size)\n",
    "print(w_query.weight.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 128])\n"
     ]
    }
   ],
   "source": [
    "query = w_query(hidden_states)\n",
    "print(query.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각종 mask 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[3091, 3604,  206, 3958, 3760, 3590,    0,    0],\n",
    "                       [ 212, 3605,   53, 3832, 3596, 3682, 3760, 3590]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_pad_mask(seq_q, seq_k):\n",
    "    # print(seq_q)\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    # eq(zero) is PAD token\n",
    "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # batch_size x 1 x len_k(=len_q), one is masking\n",
    "    return pad_attn_mask.expand(batch_size, len_q, len_k)  # batch_size x len_q x len_k\n",
    "\n",
    "def transpose_for_attention_scores(x):\n",
    "    new_x_shape = x.size()[:-1] + (num_heads, head_size)\n",
    "    x = x.view(new_x_shape)\n",
    "    return x.permute(0, 2, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 8])\n",
      "torch.Size([2, 8, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "attention_mask = get_attn_pad_mask(inputs, inputs)\n",
    "print(attention_mask.size())\n",
    "attention_mask = attention_mask.unsqueeze(1).repeat(1, num_heads, 1, 1)\n",
    "print(attention_mask.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### repeat 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 8])\n",
      "tensor([[False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True]])\n"
     ]
    }
   ],
   "source": [
    "# expand 와 역할이 비슷\n",
    "attn_mask2 = inputs.eq(0).unsqueeze(1).repeat(1, inputs.size()[1], 1)\n",
    "print(attn_mask2.size())\n",
    "print(attn_mask2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True]])\n"
     ]
    }
   ],
   "source": [
    "print(attention_mask[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = nn.Embedding(5000, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### masked_fill_ 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 128])\n",
      "torch.Size([2, 8, 8, 16])\n",
      "torch.Size([2, 8, 8, 8])\n",
      "tensor([[ 4.6761,  0.0964, -0.8392,  1.0350,  0.6139, -0.7481,  1.7292,  1.7292],\n",
      "        [ 0.0964,  5.7820, -0.2166,  0.5408,  0.4307, -0.2465,  1.4741,  1.4741],\n",
      "        [-0.8392, -0.2166,  5.6125, -0.5546, -0.5507, -0.0594,  0.7508,  0.7508],\n",
      "        [ 1.0350,  0.5408, -0.5546,  4.2115,  0.0281,  0.6837, -0.0087, -0.0087],\n",
      "        [ 0.6139,  0.4307, -0.5507,  0.0281,  6.2815,  0.3990, -0.3775, -0.3775],\n",
      "        [-0.7481, -0.2465, -0.0594,  0.6837,  0.3990,  2.5180, -0.5743, -0.5743],\n",
      "        [ 1.7292,  1.4741,  0.7508, -0.0087, -0.3775, -0.5743,  3.4868,  3.4868],\n",
      "        [ 1.7292,  1.4741,  0.7508, -0.0087, -0.3775, -0.5743,  3.4868,  3.4868]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[ 4.6761e+00,  9.6396e-02, -8.3923e-01,  1.0350e+00,  6.1386e-01,\n",
      "         -7.4811e-01, -1.0000e+09, -1.0000e+09],\n",
      "        [ 9.6396e-02,  5.7820e+00, -2.1659e-01,  5.4077e-01,  4.3070e-01,\n",
      "         -2.4650e-01, -1.0000e+09, -1.0000e+09],\n",
      "        [-8.3923e-01, -2.1659e-01,  5.6125e+00, -5.5461e-01, -5.5071e-01,\n",
      "         -5.9364e-02, -1.0000e+09, -1.0000e+09],\n",
      "        [ 1.0350e+00,  5.4077e-01, -5.5461e-01,  4.2115e+00,  2.8108e-02,\n",
      "          6.8371e-01, -1.0000e+09, -1.0000e+09],\n",
      "        [ 6.1386e-01,  4.3070e-01, -5.5071e-01,  2.8108e-02,  6.2815e+00,\n",
      "          3.9900e-01, -1.0000e+09, -1.0000e+09],\n",
      "        [-7.4811e-01, -2.4650e-01, -5.9364e-02,  6.8371e-01,  3.9900e-01,\n",
      "          2.5180e+00, -1.0000e+09, -1.0000e+09],\n",
      "        [ 1.7292e+00,  1.4741e+00,  7.5080e-01, -8.7306e-03, -3.7750e-01,\n",
      "         -5.7430e-01, -1.0000e+09, -1.0000e+09],\n",
      "        [ 1.7292e+00,  1.4741e+00,  7.5080e-01, -8.7306e-03, -3.7750e-01,\n",
      "         -5.7430e-01, -1.0000e+09, -1.0000e+09]], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "enc_inputs = word_embeddings(inputs)\n",
    "print(enc_inputs.size())\n",
    "q = transpose_for_attention_scores(enc_inputs)\n",
    "k = transpose_for_attention_scores(enc_inputs)\n",
    "v = transpose_for_attention_scores(enc_inputs)\n",
    "print(q.size())\n",
    "scores = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(head_size)\n",
    "print(scores.size())\n",
    "print(scores[0][0])\n",
    "scores.masked_fill_(attention_mask, -1e9) # inplace=True 라고 이해\n",
    "print(scores[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n",
      "torch.Size([2, 8])\n",
      "tensor([[False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False]])\n",
      "torch.Size([2, 8])\n",
      "tensor([[1, 2, 3, 4, 5, 6, 0, 0],\n",
      "        [1, 2, 3, 4, 5, 6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "position_ids = torch.arange(inputs.size()[1], dtype=torch.long, device=inputs.device)\n",
    "print(position_ids)\n",
    "position_ids = position_ids.unsqueeze(0).expand_as(inputs) + 1\n",
    "position_mask = inputs.eq(0)\n",
    "print(position_mask.size())\n",
    "print(position_mask)\n",
    "position_ids.masked_fill_(position_mask, 0)\n",
    "print(position_ids.size())\n",
    "print(position_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "position = torch.arange(inputs.size()[1], dtype=torch.long, device=inputs.device)\n",
    "print(position)\n",
    "position = position.unsqueeze(0).expand_as(input_ids) + 1\n",
    "print(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 8])\n",
      "tensor([[[False, False, False, False, False, False,  True,  True],\n",
      "         [False, False, False, False, False, False,  True,  True],\n",
      "         [False, False, False, False, False, False,  True,  True],\n",
      "         [False, False, False, False, False, False,  True,  True],\n",
      "         [False, False, False, False, False, False,  True,  True],\n",
      "         [False, False, False, False, False, False,  True,  True],\n",
      "         [False, False, False, False, False, False,  True,  True],\n",
      "         [False, False, False, False, False, False,  True,  True]],\n",
      "\n",
      "        [[False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False]]])\n",
      "torch.Size([2, 8, 8])\n",
      "tensor([[[False, False, False, False, False, False,  True,  True],\n",
      "         [False, False, False, False, False, False,  True,  True],\n",
      "         [False, False, False, False, False, False,  True,  True],\n",
      "         [False, False, False, False, False, False,  True,  True],\n",
      "         [False, False, False, False, False, False,  True,  True],\n",
      "         [False, False, False, False, False, False,  True,  True],\n",
      "         [False, False, False, False, False, False,  True,  True],\n",
      "         [False, False, False, False, False, False,  True,  True]],\n",
      "\n",
      "        [[False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False],\n",
      "         [False, False, False, False, False, False, False, False]]])\n"
     ]
    }
   ],
   "source": [
    "batch_size, seq_length = inputs.size()\n",
    "mask1 = inputs.eq(0).unsqueeze(1).repeat(1, seq_length, 1)\n",
    "print(mask1.size())\n",
    "print(mask1)\n",
    "mask2 = inputs.eq(0).unsqueeze(1).expand(-1, seq_length, seq_length)\n",
    "print(mask2.size())\n",
    "print(mask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False, False, False, False, False, False,  True,  True],\n",
       "         [False, False, False, False, False, False,  True,  True],\n",
       "         [False, False, False, False, False, False,  True,  True],\n",
       "         [False, False, False, False, False, False,  True,  True],\n",
       "         [False, False, False, False, False, False,  True,  True],\n",
       "         [False, False, False, False, False, False,  True,  True],\n",
       "         [False, False, False, False, False, False,  True,  True],\n",
       "         [False, False, False, False, False, False,  True,  True]],\n",
       "\n",
       "        [[False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_attn_pad_mask(inputs, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.functional.relu vs nn.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3091, 3604,  206, 3958, 3760, 3590,    0,    0],\n",
       "        [ 212, 3605,   53, 3832, 3596, 3682, 3760, 3590]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu1 = nn.functional.relu\n",
    "relu2 = nn.ReLU()\n",
    "relu2(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### triu 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 8])\n",
      "tensor([[[0, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [0, 0, 1, 1, 1, 1, 1, 1],\n",
      "         [0, 0, 0, 1, 1, 1, 1, 1],\n",
      "         [0, 0, 0, 0, 1, 1, 1, 1],\n",
      "         [0, 0, 0, 0, 0, 1, 1, 1],\n",
      "         [0, 0, 0, 0, 0, 0, 1, 1],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 1],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [0, 0, 1, 1, 1, 1, 1, 1],\n",
      "         [0, 0, 0, 1, 1, 1, 1, 1],\n",
      "         [0, 0, 0, 0, 1, 1, 1, 1],\n",
      "         [0, 0, 0, 0, 0, 1, 1, 1],\n",
      "         [0, 0, 0, 0, 0, 0, 1, 1],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 1],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0]]])\n"
     ]
    }
   ],
   "source": [
    "seq_length = inputs.size()[1]\n",
    "look_ahead_attention_mask = torch.ones_like(inputs).unsqueeze(1).expand(-1, seq_length, seq_length)\n",
    "look_ahead_attention_mask = look_ahead_attention_mask.triu(diagonal=1)\n",
    "print(look_ahead_attention_mask.size())\n",
    "print(look_ahead_attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1, 1, 1, 1, 1, 2, 2],\n",
       "         [0, 0, 1, 1, 1, 1, 2, 2],\n",
       "         [0, 0, 0, 1, 1, 1, 2, 2],\n",
       "         [0, 0, 0, 0, 1, 1, 2, 2],\n",
       "         [0, 0, 0, 0, 0, 1, 2, 2],\n",
       "         [0, 0, 0, 0, 0, 0, 2, 2],\n",
       "         [0, 0, 0, 0, 0, 0, 1, 2],\n",
       "         [0, 0, 0, 0, 0, 0, 1, 1]],\n",
       "\n",
       "        [[0, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_ahead_attention_mask + mask1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Float (got Long)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-812dc4a3b126>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlook_ahead_attention_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: expected Float (got Long)"
     ]
    }
   ],
   "source": [
    "torch.FloatTensor(look_ahead_attention_mask.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_ahead_attention_mask.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "inputs2 = inputs.to('cuda:0')\n",
    "print(inputs2.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "embedding = nn.Embedding(5000, 128).to('cuda:0')\n",
    "output = embedding(inputs2)\n",
    "print(output.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check max and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 6])\n",
      "tensor([[[-0.6938,  0.1457, -0.9835,  1.3099, -0.9390,  0.8756],\n",
      "         [ 0.2593,  0.8409, -0.4726,  0.1268,  0.7458, -0.0990],\n",
      "         [-0.9609, -0.1394,  0.7400,  0.9022,  0.7582,  2.0940],\n",
      "         [ 0.2643, -1.0782, -0.8420,  0.7802, -0.3221,  0.2543]],\n",
      "\n",
      "        [[ 0.6597, -1.5837,  1.6594, -1.6289,  1.5789,  0.3306],\n",
      "         [-0.0280,  0.0883,  0.6994,  1.8595, -1.4196, -0.1731],\n",
      "         [ 1.5204, -1.1727,  1.0850, -0.7173,  1.0063, -0.5371],\n",
      "         [-0.0202, -0.9994, -0.2342, -0.3674,  0.2583, -0.3927]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 4, 6)\n",
    "print(x.size())\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 6])\n",
      "torch.return_types.max(\n",
      "values=tensor([[[0.2643, 0.8409, 0.7400, 1.3099, 0.7582, 2.0940]],\n",
      "\n",
      "        [[1.5204, 0.0883, 1.6594, 1.8595, 1.5789, 0.3306]]]),\n",
      "indices=tensor([[[3, 1, 2, 0, 2, 2]],\n",
      "\n",
      "        [[2, 1, 0, 1, 0, 0]]]))\n"
     ]
    }
   ],
   "source": [
    "x1 = x.data.max(1, keepdim=True)\n",
    "print(x1[0].size())\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n",
      "tensor([[3, 3, 5, 2],\n",
      "        [2, 3, 2, 4]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.max(x, dim=-1)[1]\n",
    "print(y.size())\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.CrossEntoropyLoss() 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "tensor([[ 1.4663,  1.8633, -1.3971,  0.9727, -0.8936],\n",
      "        [-0.0059,  0.7120, -0.6675,  0.5047,  0.7541],\n",
      "        [-0.8697, -1.3655,  0.5656, -0.2357, -0.2611]], requires_grad=True)\n",
      "torch.Size([3]) torch.LongTensor\n",
      "tensor([0, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# 이미 Softmax 연산이 들어가 있다!!! 기억해야할 중요한 특징\n",
    "x = torch.randn(3, 5, requires_grad=True)\n",
    "print(x.type())\n",
    "print(x)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print(target.size(), target.type())\n",
    "print(target)\n",
    "# x [학습 데이터 개수, 예측할 클래스 개수]  \n",
    "# target [학습 데이터 개수]  각 요소의 값의 범위는 0<= 요소 값 < 예측할 클래스 개수\n",
    "output = loss(x, target) \n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3157, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### contiguous 역할 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[ 0.7520,  0.9209,  1.7477,  0.2112, -0.7485, -1.6528,  1.4142, -0.2038,\n",
      "         -0.4447, -1.2773, -0.7338,  0.2586]])\n",
      "x1 torch.Size([6, 1, 2]) tensor([[[ 0.7520,  0.9209]],\n",
      "\n",
      "        [[ 1.7477,  0.2112]],\n",
      "\n",
      "        [[-0.7485, -1.6528]],\n",
      "\n",
      "        [[ 1.4142, -0.2038]],\n",
      "\n",
      "        [[-0.4447, -1.2773]],\n",
      "\n",
      "        [[-0.7338,  0.2586]]])\n",
      "x2 torch.Size([2, 6]) tensor([[ 0.7520,  0.9209,  1.7477,  0.2112, -0.7485, -1.6528],\n",
      "        [ 1.4142, -0.2038, -0.4447, -1.2773, -0.7338,  0.2586]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 12)\n",
    "print('x', x)\n",
    "x1 = x.view(6, 1, 2)  # view 는 contiguous 관계없이 잘만 연산된다...\n",
    "print('x1', x1.size(), x1)\n",
    "x2 = x1.view(-1, 6)\n",
    "print('x2', x2.size(), x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[-1.3997,  0.8185,  1.1836,  2.0959],\n",
      "        [ 0.5977, -0.2876, -0.8078,  1.1232],\n",
      "        [-0.1020, -1.0201, -0.9303,  0.8226]])\n",
      "x1 torch.Size([4, 3]) tensor([[-1.3997,  0.5977, -0.1020],\n",
      "        [ 0.8185, -0.2876, -1.0201],\n",
      "        [ 1.1836, -0.8078, -0.9303],\n",
      "        [ 2.0959,  1.1232,  0.8226]])\n",
      "x2 torch.Size([1, 12]) tensor([[-1.3997,  0.5977, -0.1020,  0.8185, -0.2876, -1.0201,  1.1836, -0.8078,\n",
      "         -0.9303,  2.0959,  1.1232,  0.8226]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "print('x', x)\n",
    "x1 = x.T.contiguous()\n",
    "print('x1', x1.size(), x1)\n",
    "x2 = x1.view(-1, 12)\n",
    "print('x2', x2.size(), x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[-0.3530, -0.7585,  0.1002,  0.1007],\n",
      "        [-0.3664,  0.7023, -1.3625,  0.1680],\n",
      "        [-0.5170, -0.6264, -0.8493,  0.7772]])\n",
      "x1 torch.Size([4, 3]) tensor([[-0.3530, -0.3664, -0.5170],\n",
      "        [-0.7585,  0.7023, -0.6264],\n",
      "        [ 0.1002, -1.3625, -0.8493],\n",
      "        [ 0.1007,  0.1680,  0.7772]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-11fd719a0e10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'x1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mx2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'x2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "print('x', x)\n",
    "x1 = x.T\n",
    "print('x1', x1.size(), x1)\n",
    "x2 = x1.view(-1, 12)\n",
    "print('x2', x2.size(), x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### softmax 함수를 2번 거치면 안되는 이유!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1489, 0.8749, 1.7694, 0.0402]])\n",
      "tensor([[0.2532, 0.1925, 0.4708, 0.0835]])\n",
      "tensor([[0.2482, 0.2336, 0.3086, 0.2095]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 4)\n",
    "print(x)\n",
    "y = nn.Softmax(dim=-1)(x)\n",
    "print(y)\n",
    "z = nn.Softmax(dim=-1)(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특정 인덱스에 있는 배열들끼리 loss 함수 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[15, 94, 79, 12, 63,  0,  0,  0,  0,  0],\n",
      "        [45, 78, 27, 58, 97,  0,  0,  0,  0,  0],\n",
      "        [46, 51, 32, 46, 44,  0,  0,  0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "logits = torch.cat((torch.randint(low=1, high=100, size=(3, 5)), torch.zeros(3, 5)), dim=1).long()\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.5601, -0.5249,  1.2889,  ...,  0.3411, -1.3962, -1.2489],\n",
      "         [-0.8170,  1.2406, -0.9008,  ...,  0.2952,  0.4377,  0.4691],\n",
      "         [ 0.7496,  0.1983, -0.4119,  ...,  0.2676, -2.1124, -0.2258],\n",
      "         ...,\n",
      "         [-0.1310, -0.9929,  0.0581,  ..., -0.5869, -2.3567, -0.0658],\n",
      "         [-0.8745,  0.6750, -0.1264,  ...,  0.1858, -1.0787, -0.3986],\n",
      "         [-0.6307,  0.9805,  0.6117,  ...,  0.7772,  0.5498, -0.5344]],\n",
      "\n",
      "        [[ 0.7131,  3.5618,  1.4272,  ...,  0.4929, -0.4648,  0.6625],\n",
      "         [ 0.5249, -1.0449, -1.0311,  ..., -1.3840,  1.6824, -0.9098],\n",
      "         [ 0.2124,  0.1566, -0.7641,  ...,  0.2226, -0.8025, -2.0636],\n",
      "         ...,\n",
      "         [-1.6686, -0.1605, -0.4563,  ..., -0.8832,  0.8574,  0.2229],\n",
      "         [ 0.4103,  0.6757,  0.5089,  ..., -0.9261, -0.8572,  0.3098],\n",
      "         [-1.4222, -0.4565,  1.1931,  ...,  0.6827,  0.6277,  0.0635]],\n",
      "\n",
      "        [[-0.9394, -0.4340, -0.1077,  ..., -1.3675,  0.1026,  0.3075],\n",
      "         [ 0.5232,  1.1724,  0.1237,  ...,  0.9998,  1.4387, -0.1562],\n",
      "         [ 0.7182, -1.1067,  0.5065,  ..., -0.6163, -0.7558, -0.4434],\n",
      "         ...,\n",
      "         [ 1.3539, -0.3944,  0.6125,  ..., -0.2243, -2.1101, -0.9757],\n",
      "         [ 2.2957, -1.1454,  1.1040,  ..., -0.3667, -0.2691,  0.0809],\n",
      "         [ 0.7480,  1.7755, -1.1381,  ..., -1.2973,  2.0661, -1.3279]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1304, -1.1497,  1.5660,  ..., -0.3146, -0.1521,  0.4511],\n",
      "         [-0.2547,  0.9857, -0.6848,  ...,  0.0287, -0.2569,  0.0931],\n",
      "         [ 0.0950, -1.2067,  0.7149,  ..., -1.2562, -1.7726, -0.2319],\n",
      "         ...,\n",
      "         [ 1.6356,  0.3279, -0.3426,  ...,  0.1398,  1.1865,  0.7656],\n",
      "         [ 1.2599, -0.0375,  2.0684,  ...,  1.2232, -0.0797,  1.2744],\n",
      "         [ 1.2467, -0.2271,  0.6374,  ...,  0.4079, -0.9201,  0.3263]],\n",
      "\n",
      "        [[ 0.3065, -0.9915, -1.0108,  ...,  0.6105,  0.8636, -1.3481],\n",
      "         [-0.4127,  0.8104,  0.4218,  ..., -0.1863, -1.1182,  0.0422],\n",
      "         [-0.0187,  0.8698, -1.4840,  ..., -0.6874, -0.3200, -0.4301],\n",
      "         ...,\n",
      "         [ 0.2210, -1.5515, -0.6805,  ...,  1.0053, -0.5699,  0.9838],\n",
      "         [ 0.3762, -2.2189,  0.7014,  ...,  0.6822, -1.2545, -1.4760],\n",
      "         [ 1.8043,  0.1991, -0.2771,  ..., -0.9077, -0.6103,  1.1408]],\n",
      "\n",
      "        [[-0.9618, -1.4405,  1.4634,  ..., -0.4754, -0.1155,  0.9216],\n",
      "         [ 0.0253,  1.0302, -0.9436,  ..., -0.1056,  0.7917, -1.2510],\n",
      "         [ 0.2725, -0.7670, -0.4378,  ...,  1.1119,  0.5676, -1.3571],\n",
      "         ...,\n",
      "         [ 0.3650,  0.6266, -0.2302,  ..., -1.1809, -0.2962,  0.7766],\n",
      "         [ 0.6835,  3.0657,  1.2768,  ...,  1.4985, -1.4069, -1.1232],\n",
      "         [ 0.2143,  0.6290,  0.7461,  ...,  0.1030, -0.6531,  0.1062]]])\n"
     ]
    }
   ],
   "source": [
    "logits = torch.randn(32, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.cat((torch.randint(63, (32, 40)), torch.zeros(32, 24).long()), dim=1)\n",
    "#print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits torch.Size([2048, 64])\n",
      "target torch.Size([2048])\n",
      "tensor(4.6720)\n"
     ]
    }
   ],
   "source": [
    "logits = logits.view(-1, 64)\n",
    "print('logits', logits.size())\n",
    "target = target.view(-1)\n",
    "print('target', target.size())\n",
    "loss = criterion(logits, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([55, 58, 40, 53,  9,  0,  0,  0, 30,  2, 57, 60, 23,  0,  0,  0])\n",
      "tensor([False, False, False, False, False,  True,  True,  True, False, False,\n",
      "        False, False, False,  True,  True,  True])\n",
      "tensor([ True,  True,  True,  True,  True, False, False, False,  True,  True,\n",
      "         True,  True,  True, False, False, False])\n",
      "tensor([0, 0, 0, 0, 0, 0])\n",
      "tensor([55, 58, 40, 53,  9, 30,  2, 57, 60, 23])\n"
     ]
    }
   ],
   "source": [
    "print(target)\n",
    "mask = target.eq(0)\n",
    "mask2 = target.gt(0)\n",
    "print(mask)\n",
    "print(mask2)\n",
    "print(torch.masked_select(target, mask))\n",
    "print(torch.masked_select(target, mask2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "indices = target.nonzero()\n",
    "print(indices.size())\n",
    "indices = indices.squeeze(1)\n",
    "print(indices.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  8,  9, 10, 11, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-4.4530e-01, -2.0959e+00,  3.4911e-01,  1.1928e+00,  1.8318e+00,\n",
       "         1.0213e+00,  8.9384e-01, -1.5533e-03,  4.3959e-01, -5.1688e-01,\n",
       "        -3.6100e-01, -5.7435e-01,  1.3810e+00, -9.9748e-01,  9.3622e-01,\n",
       "         5.8957e-01, -9.8576e-01,  2.1106e+00, -7.5180e-01, -6.9673e-01,\n",
       "         9.5892e-01,  3.6880e-02,  3.0920e-01,  1.2280e-01, -6.3096e-01,\n",
       "        -4.0947e-03, -1.1701e+00, -8.1369e-01,  1.3854e+00, -1.0662e+00,\n",
       "         4.1882e-01, -8.3795e-01,  1.9905e-02,  5.0381e-02, -5.8051e-03,\n",
       "        -2.6111e-01, -2.1081e-01,  2.6515e-01, -1.7769e+00,  1.4315e+00,\n",
       "         9.8287e-01, -1.4567e+00, -1.8326e+00,  1.2404e+00,  8.7852e-01,\n",
       "        -4.3018e-01,  1.0892e+00,  2.8672e-01,  1.0150e+00,  8.9820e-01,\n",
       "         2.9182e-01, -4.4006e-01,  6.1617e-01,  2.3243e-01, -2.4432e-02,\n",
       "        -1.1542e+00,  6.4300e-02,  7.9511e-01, -1.1673e+00,  8.3426e-01,\n",
       "        -1.7161e-01, -1.5478e+00, -5.3831e-01, -1.0625e+00])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero_select = target.nonzero().squeeze(1)\n",
    "print(nonzero_select)\n",
    "logits.index_select(0, nonzero_select)[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.4530e-01, -2.0959e+00,  3.4911e-01,  1.1928e+00,  1.8318e+00,\n",
       "         1.0213e+00,  8.9384e-01, -1.5533e-03,  4.3959e-01, -5.1688e-01,\n",
       "        -3.6100e-01, -5.7435e-01,  1.3810e+00, -9.9748e-01,  9.3622e-01,\n",
       "         5.8957e-01, -9.8576e-01,  2.1106e+00, -7.5180e-01, -6.9673e-01,\n",
       "         9.5892e-01,  3.6880e-02,  3.0920e-01,  1.2280e-01, -6.3096e-01,\n",
       "        -4.0947e-03, -1.1701e+00, -8.1369e-01,  1.3854e+00, -1.0662e+00,\n",
       "         4.1882e-01, -8.3795e-01,  1.9905e-02,  5.0381e-02, -5.8051e-03,\n",
       "        -2.6111e-01, -2.1081e-01,  2.6515e-01, -1.7769e+00,  1.4315e+00,\n",
       "         9.8287e-01, -1.4567e+00, -1.8326e+00,  1.2404e+00,  8.7852e-01,\n",
       "        -4.3018e-01,  1.0892e+00,  2.8672e-01,  1.0150e+00,  8.9820e-01,\n",
       "         2.9182e-01, -4.4006e-01,  6.1617e-01,  2.3243e-01, -2.4432e-02,\n",
       "        -1.1542e+00,  6.4300e-02,  7.9511e-01, -1.1673e+00,  8.3426e-01,\n",
       "        -1.7161e-01, -1.5478e+00, -5.3831e-01, -1.0625e+00])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([55, 58, 40, 53,  9,  0,  0,  0, 30,  2, 57, 60, 23,  0,  0,  0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([55, 58, 40, 53,  9, 30,  2, 57, 60, 23])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(target)\n",
    "target.index_select(0, nonzero_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12)\n",
      "torch.Size([12, 64])\n"
     ]
    }
   ],
   "source": [
    "idx = target.nonzero().max()\n",
    "print(idx)\n",
    "print(logits[:idx].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.4530e-01, -2.0959e+00,  3.4911e-01,  1.1928e+00,  1.8318e+00,\n",
       "         1.0213e+00,  8.9384e-01, -1.5533e-03,  4.3959e-01, -5.1688e-01,\n",
       "        -3.6100e-01, -5.7435e-01,  1.3810e+00, -9.9748e-01,  9.3622e-01,\n",
       "         5.8957e-01, -9.8576e-01,  2.1106e+00, -7.5180e-01, -6.9673e-01,\n",
       "         9.5892e-01,  3.6880e-02,  3.0920e-01,  1.2280e-01, -6.3096e-01,\n",
       "        -4.0947e-03, -1.1701e+00, -8.1369e-01,  1.3854e+00, -1.0662e+00,\n",
       "         4.1882e-01, -8.3795e-01,  1.9905e-02,  5.0381e-02, -5.8051e-03,\n",
       "        -2.6111e-01, -2.1081e-01,  2.6515e-01, -1.7769e+00,  1.4315e+00,\n",
       "         9.8287e-01, -1.4567e+00, -1.8326e+00,  1.2404e+00,  8.7852e-01,\n",
       "        -4.3018e-01,  1.0892e+00,  2.8672e-01,  1.0150e+00,  8.9820e-01,\n",
       "         2.9182e-01, -4.4006e-01,  6.1617e-01,  2.3243e-01, -2.4432e-02,\n",
       "        -1.1542e+00,  6.4300e-02,  7.9511e-01, -1.1673e+00,  8.3426e-01,\n",
       "        -1.7161e-01, -1.5478e+00, -5.3831e-01, -1.0625e+00])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[:idx+1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
