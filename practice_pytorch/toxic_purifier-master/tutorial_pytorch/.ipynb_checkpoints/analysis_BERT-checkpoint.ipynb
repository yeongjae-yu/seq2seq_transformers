{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT pytorch 버전에 쓰인 각종 문법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT model 의 실행 구조\n",
    "#### hugging face 코드를 보면 안쪽에서부터 class 구조를 만들고 있음 \n",
    "#### 위에서부터 순차적으로 봐도 무방 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. tf checkpoint 을 pytorch checkpoint로 변환\n",
    "    def load_tf_weights_in_bert\n",
    "\n",
    "2. Bert의 기본 정보 규격 생성\n",
    "    class BertConfig \n",
    "        class BertLayerNorm 클래스 선언\n",
    "\n",
    "3. BertModel 실행\n",
    "    class BertModel(class BertPreTrainModel 상속)\n",
    "        class BertEmbeddings\n",
    "        class BertEncoder\n",
    "            class BertLayer\n",
    "                class BertAttention\n",
    "                    class BertSelfAttention\n",
    "                    class BertSelfOutput\n",
    "                class BertIntermediate\n",
    "                class BertOutput\n",
    "        class BertPooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import copy\n",
    "import json\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import tempfile\n",
    "import sys\n",
    "from io import open\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __init__(생성자) 선언 시 보이는 super()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### child class 에서 parent class 의 내용을 사용하고 싶을 경우에 이용"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "class BertLayerNorm(nn.Module):\n",
    "        def __init__(self, hidden_size, eps=1e-12):\n",
    "            super(BertLayerNorm, self).__init__()\n",
    "            self.weight = nn.Parameter(torch.ones(hidden_size))\n",
    "            self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
    "            self.variance_epsilon = eps\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 오버라이딩 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class father():  # 부모 클래스\n",
    "    def handsome(self):\n",
    "        print(\"잘생겼다\")\n",
    "        \n",
    "class brother(father):  # 자식클래스(부모클래스) 아빠매소드를 상속받겠다\n",
    "    '''아들'''\n",
    "\n",
    "class sister(father):  # 자식클래스(부모클래스) 아빠매소드를 상속받겠다\n",
    "    def pretty(self):\n",
    "        print(\"예쁘다\")\n",
    " \n",
    "    def handsome(self):\n",
    "        '''물려받았어요'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "잘생겼다\n",
      "예쁘다\n"
     ]
    }
   ],
   "source": [
    "brother = brother()\n",
    "brother.handsome()\n",
    " \n",
    "girl = sister()\n",
    "girl.handsome()  # 오버라이딩으로 실행 내용이 수정돼 출력 내용 없음\n",
    "girl.pretty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### super로 parent class method 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class father():  # 부모 클래스\n",
    "    def handsome(self):\n",
    "        print(\"잘생겼다\")\n",
    "\n",
    "class brother(father):  # 자식클래스(부모클래스) 아빠매소드를 상속받겠다\n",
    "    '''아들'''\n",
    "\n",
    "class sister(father):  # 자식클래스(부모클래스) 아빠매소드를 상속받겠다\n",
    "    def pretty(self):\n",
    "        print(\"예쁘다\")\n",
    " \n",
    "    def handsome(self):\n",
    "        super().handsome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "잘생겼다\n",
      "잘생겼다\n",
      "예쁘다\n"
     ]
    }
   ],
   "source": [
    "brother = brother()\n",
    "brother.handsome()\n",
    " \n",
    "girl = sister()\n",
    "girl.handsome()\n",
    "girl.pretty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 응용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mother():\n",
    "    def __init__(self, who):\n",
    "        self.who = who\n",
    "        \n",
    "    def pretty(self):\n",
    "        print(\"{}를 닮아 예쁘다\".format(self.who))\n",
    "\n",
    "class daughter(mother):\n",
    "    def __init__(self, who, where):\n",
    "        super().__init__(who)\n",
    "        self.where = where\n",
    "        \n",
    "    def part(self):\n",
    "        print(\"{} 말이야\".format(self.where))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "엄마를 닮아 예쁘다\n",
      "얼굴 말이야\n"
     ]
    }
   ],
   "source": [
    "girl = daughter('엄마', '얼굴')\n",
    "girl.pretty()\n",
    "girl.part()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mother():\n",
    "    def __init__(self, who):\n",
    "        self.who = who\n",
    "        \n",
    "    def pretty(self):\n",
    "        print(\"{}를 닮아 예쁘다\".format(self.who))\n",
    "\n",
    "class daughter(mother):\n",
    "    def __init__(self, who, where):\n",
    "        super().__init__(who)\n",
    "        self.where = where\n",
    "        \n",
    "    def part(self):\n",
    "        print(\"{} 말이야\".format(self.where))\n",
    "        \n",
    "    def pretty(self):\n",
    "        super().pretty()\n",
    "        self.part()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "엄마를 닮아 예쁘다\n",
      "얼굴 말이야\n"
     ]
    }
   ],
   "source": [
    "girl = daughter('엄마', '얼굴')\n",
    "girl.pretty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중 상속에서 super()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 여러 번의 상속으로 class A 2번 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class D __init__()\n",
      "Class B __init__()\n",
      "Class A __init__()\n",
      "Class C __init__()\n",
      "Class A __init__()\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        print(\"Class A __init__()\")\n",
    "\n",
    "class B(A):\n",
    "    def __init__(self):\n",
    "        print(\"Class B __init__()\")\n",
    "        A.__init__(self)\n",
    "\n",
    "class C(A):\n",
    "    def __init__(self):\n",
    "        print(\"Class C __init__()\")\n",
    "        A.__init__(self)\n",
    "\n",
    "class D(B, C):\n",
    "    def __init__(self):\n",
    "        print(\"Class D __init__()\")\n",
    "        B.__init__(self)\n",
    "        C.__init__(self)\n",
    "\n",
    "d = D()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### super() 를 통해 최상단 클래스 한 번만 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class D __init__()\n",
      "Class B __init__()\n",
      "Class C __init__()\n",
      "Class A __init__()\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        print(\"Class A __init__()\")\n",
    "\n",
    "class B(A):\n",
    "    def __init__(self):\n",
    "        print(\"Class B __init__()\")\n",
    "        super(B, self).__init__()\n",
    "\n",
    "class C(A):\n",
    "    def __init__(self):\n",
    "        print(\"Class C __init__()\")\n",
    "        super(C, self).__init__()\n",
    "\n",
    "class D(B, C):\n",
    "    def __init__(self):\n",
    "        print(\"Class D __init__()\")\n",
    "        super(D, self).__init__()\n",
    "\n",
    "d = D()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 생각해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class B __init__()\n",
      "Class C __init__()\n",
      "Class A __init__()\n",
      "Class D __init__()\n",
      "Class C __init__()\n",
      "Class A __init__()\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        print(\"Class A __init__()\")\n",
    "\n",
    "class B(A):\n",
    "    def __init__(self):\n",
    "        print(\"Class B __init__()\")\n",
    "        super(B, self).__init__()\n",
    "\n",
    "class C(A):\n",
    "    def __init__(self):\n",
    "        print(\"Class C __init__()\")\n",
    "        super(C, self).__init__()\n",
    "\n",
    "class D(B, C):\n",
    "    def __init__(self):\n",
    "        B.__init__(self)\n",
    "        print(\"Class D __init__()\")\n",
    "        C.__init__(self)\n",
    "\n",
    "d = D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class B __init__()\n",
      "Class C __init__()\n",
      "Class A __init__()\n",
      "Class D __init__()\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        print(\"Class A __init__()\")\n",
    "\n",
    "class B(A):\n",
    "    def __init__(self):\n",
    "        print(\"Class B __init__()\")\n",
    "        super().__init__()\n",
    "\n",
    "class C(A):\n",
    "    def __init__(self):\n",
    "        print(\"Class C __init__()\")\n",
    "        super().__init__()\n",
    "\n",
    "class D(B, C):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        print(\"Class D __init__()\")\n",
    "        \n",
    "\n",
    "d = D()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실제 코딩에서 자주 쓰이는 상속 형태 (nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class B __init__()\n",
      "Class A __init__()\n",
      "Class C __init__()\n",
      "Class A __init__()\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        print(\"Class A __init__()\")\n",
    "\n",
    "class B(A):\n",
    "    def __init__(self):\n",
    "        print(\"Class B __init__()\")\n",
    "        A.__init__(self)\n",
    "\n",
    "class C(A):\n",
    "    def __init__(self):\n",
    "        print(\"Class C __init__()\")\n",
    "        A.__init__(self)\n",
    "        \n",
    "b = B()\n",
    "c = C()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class B __init__()\n",
      "Class A __init__()\n",
      "Class C __init__()\n",
      "Class A __init__()\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        print(\"Class A __init__()\")\n",
    "\n",
    "class B(A):\n",
    "    def __init__(self):\n",
    "        print(\"Class B __init__()\")\n",
    "        super(B, self).__init__()\n",
    "\n",
    "class C(A):\n",
    "    def __init__(self):\n",
    "        print(\"Class C __init__()\")\n",
    "        super(C, self).__init__()\n",
    "\n",
    "b = B()\n",
    "c = C()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class B __init__()\n",
      "Class A __init__()\n",
      "Class C __init__()\n",
      "Class A __init__()\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        print(\"Class A __init__()\")\n",
    "\n",
    "class B(A):\n",
    "    def __init__(self):\n",
    "        print(\"Class B __init__()\")\n",
    "        super().__init__()\n",
    "\n",
    "class C(A):\n",
    "    def __init__(self):\n",
    "        print(\"Class C __init__()\")\n",
    "        super().__init__()\n",
    "\n",
    "b = B()\n",
    "c = C()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Parameter(텐서 객체, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텐서 객체가 module의 attribute를 사용하기 위해서 이용\n",
    "#### requires_grad True가 디폴트로 변화도 추적 가능"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class BertLayerNorm(nn.Module):\n",
    "        def __init__(self, hidden_size, eps=1e-12):\n",
    "            super(BertLayerNorm, self).__init__()\n",
    "            self.weight = nn.Parameter(torch.ones(hidden_size))\n",
    "            self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
    "            self.variance_epsilon = eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1., 1., 1., 1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param1 = nn.Parameter(torch.ones(5))\n",
    "param1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param2 = nn.Parameter(torch.zeros(5))\n",
    "param2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor.mean(input, dim, keepdim=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### row 값들의 평균을 계산, input은 자기 자신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.6759e-01, 7.1681e-01, 1.4085e-04, 9.5262e-01, 2.3398e-01],\n",
       "        [3.6850e-01, 7.8970e-01, 8.4010e-01, 6.7154e-01, 4.8803e-01]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2, 5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dim 은 평균 내릴 rank를 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4180, 0.7533, 0.4201, 0.8121, 0.3610])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = x.mean(0)\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4742, 0.6316])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = x.mean(1)\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### keepdim 이 True이면 원래 차원 규격을 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4742],\n",
       "        [0.6316]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3 = x.mean(-1, keepdim=True)\n",
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2836, 0.1740, 0.6098, 0.5093],\n",
       "         [0.0673, 0.2343, 0.6839, 0.7901],\n",
       "         [0.4197, 0.4017, 0.3716, 0.4157]],\n",
       "\n",
       "        [[0.3331, 0.2045, 0.0594, 0.0957],\n",
       "         [0.0530, 0.0109, 0.1657, 0.2136],\n",
       "         [0.6505, 0.6651, 0.6175, 0.6870]]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2, 3, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3942],\n",
       "         [0.4439],\n",
       "         [0.4021]],\n",
       "\n",
       "        [[0.1732],\n",
       "         [0.1108],\n",
       "         [0.6550]]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4 = x.mean(-1, keepdim=True)\n",
    "x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.sqrt(input, out=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensor 안의 각 요소들에 대해 루트를 적용한 텐서 객체 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5563,  0.1403, -0.0220],\n",
       "        [-1.1635,  0.7729,  0.2909]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   nan, 0.3746,    nan],\n",
       "        [   nan, 0.8792, 0.5394]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Embedding(총 단어의 갯수, 임베딩할 벡터 차원)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 고정된 단어 사전에 임베딩할 weight를 저장할 lookup table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 2.1487, -2.0854, -0.0240, -1.4967, -0.9739, -1.0213,  1.0601, -1.1535],\n",
       "        [-0.8450,  0.6175, -0.3833, -0.5997, -1.0670,  0.7624,  0.6398, -1.7637],\n",
       "        [-0.6543,  0.9907,  0.0610,  2.3914, -0.0079,  0.1553,  2.2415, -0.0107],\n",
       "        [ 0.9340,  1.7949,  0.4663, -2.3766, -0.7469,  0.5045,  1.6657, -0.9562],\n",
       "        [-0.6904, -0.3072, -0.0780,  0.2416, -0.8489, -0.3077,  0.1233,  0.6495],\n",
       "        [ 0.8699,  0.4275, -0.6509, -0.5794,  0.0172, -1.2987,  0.0784, -0.5232],\n",
       "        [ 1.6806, -0.2645, -0.6750,  0.6117,  1.0130,  2.5118, -0.9972, -0.7037],\n",
       "        [ 0.4704,  0.7933, -0.5795,  0.9972, -1.3991,  0.6818, -0.1558, -0.9399],\n",
       "        [-1.4944, -0.8453,  1.7152,  0.0736,  0.6591, -0.7722, -0.2458, -1.9559],\n",
       "        [ 1.0944, -0.6446, -0.3205, -0.2747,  0.3047, -0.0378,  0.5062,  0.4221]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed1 = nn.Embedding(10, 8)\n",
    "embed1.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### padding_idx 에 지정한 index의 값들은 무조건 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.1690,  0.1047,  2.1901,  1.3962,  0.2741, -0.5491, -0.2370, -0.2545],\n",
       "        [ 0.7586, -0.5991, -0.4017, -1.6649, -0.7006, -0.2541, -0.1193, -1.4311],\n",
       "        [-0.6885,  1.7901, -0.6420,  1.3866, -0.2242, -2.7974,  0.1684,  0.7262],\n",
       "        [ 1.0062,  0.2971, -0.9541, -2.0617, -1.4385, -0.0613, -1.2690,  0.6394],\n",
       "        [ 0.6941,  1.1420,  0.2144,  0.1156,  0.5988,  2.0249, -1.1006, -0.6832],\n",
       "        [-0.3595, -0.3049, -0.0070, -0.2759,  0.6016, -0.4880, -0.3908,  0.5550],\n",
       "        [ 0.5912,  0.6910, -0.6278, -0.4928,  1.5725,  1.3432,  0.8676, -0.0503],\n",
       "        [-0.7057,  0.8965, -2.3492, -0.3322,  1.8872,  1.1978, -0.6464,  0.2613],\n",
       "        [-1.1715,  0.1227, -2.4001,  0.7240, -1.6506,  2.4978,  1.5286, -0.4391]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed2 = nn.Embedding(10, 8, padding_idx=0)\n",
    "embed2.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.arange(start=0, end, step=1, dtype=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### numpy의  arange 함수와 비슷한 기능\n",
    "#### [start, end) 의 1-D tensor 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(2, 7)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 차원 규격을 바로 하고 싶을 때 팁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(12).view(3, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bert코드에서 device는 cpu 혹은 gpu 를 쓸 지 설정하는 인자임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor.unsqueeze(input, dim, out=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 원하는 dimension의 위치에 dimension을 추가하는 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0791,  2.5146],\n",
       "         [ 1.2468,  0.5602],\n",
       "         [-0.5160, -1.2563]],\n",
       "\n",
       "        [[-0.0624, -0.4611],\n",
       "         [ 0.1054, -0.8319],\n",
       "         [ 0.0084, -0.7752]]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0791,  2.5146],\n",
       "          [ 1.2468,  0.5602],\n",
       "          [-0.5160, -1.2563]],\n",
       "\n",
       "         [[-0.0624, -0.4611],\n",
       "          [ 0.1054, -0.8319],\n",
       "          [ 0.0084, -0.7752]]]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = x.unsqueeze(0)\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 2])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0791],\n",
       "          [ 2.5146]],\n",
       "\n",
       "         [[ 1.2468],\n",
       "          [ 0.5602]],\n",
       "\n",
       "         [[-0.5160],\n",
       "          [-1.2563]]],\n",
       "\n",
       "\n",
       "        [[[-0.0624],\n",
       "          [-0.4611]],\n",
       "\n",
       "         [[ 0.1054],\n",
       "          [-0.8319]],\n",
       "\n",
       "         [[ 0.0084],\n",
       "          [-0.7752]]]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = x.unsqueeze(3)\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2, 1])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0791],\n",
       "          [ 2.5146]],\n",
       "\n",
       "         [[ 1.2468],\n",
       "          [ 0.5602]],\n",
       "\n",
       "         [[-0.5160],\n",
       "          [-1.2563]]],\n",
       "\n",
       "\n",
       "        [[[-0.0624],\n",
       "          [-0.4611]],\n",
       "\n",
       "         [[ 0.1054],\n",
       "          [-0.8319]],\n",
       "\n",
       "         [[ 0.0084],\n",
       "          [-0.7752]]]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3 = x.unsqueeze(-1)\n",
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2, 1])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor.expand_as(other_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 현재 tensor를 other_tensor의  규격으로 맞춰주는 기능\n",
    "#### 확장할 규격이 없거나 1이어야 확장 가능한 것으로 보임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 확장할 규격이 다 달라 에러 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0791,  2.5146],\n",
       "          [ 1.2468,  0.5602],\n",
       "          [-0.5160, -1.2563]],\n",
       "\n",
       "         [[-0.0624, -0.4611],\n",
       "          [ 0.1054, -0.8319],\n",
       "          [ 0.0084, -0.7752]]]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4 = x.expand_as(x1)\n",
    "x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8555, 0.6935, 0.0826]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4865, 0.2137, 0.4214, 0.2160, 0.6377],\n",
       "        [0.5618, 0.2899, 0.3697, 0.8104, 0.7490]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand(2, 5)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (5) must match the existing size (3) at non-singleton dimension 1.  Target sizes: [2, 5].  Tensor sizes: [1, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-159-ed27a1ebda9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (5) must match the existing size (3) at non-singleton dimension 1.  Target sizes: [2, 5].  Tensor sizes: [1, 3]"
     ]
    }
   ],
   "source": [
    "x.expand_as(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (3) must match the existing size (5) at non-singleton dimension 1.  Target sizes: [1, 3].  Tensor sizes: [2, 5]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-160-c992afd9d282>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (3) must match the existing size (5) at non-singleton dimension 1.  Target sizes: [1, 3].  Tensor sizes: [2, 5]"
     ]
    }
   ],
   "source": [
    "y.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0004, 0.0269])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1054, 0.1722, 0.8643],\n",
       "        [0.0146, 0.4907, 0.7806],\n",
       "        [0.1931, 0.1039, 0.1156],\n",
       "        [0.9902, 0.3669, 0.4768]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand(4, 3)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (3) must match the existing size (2) at non-singleton dimension 1.  Target sizes: [4, 3].  Tensor sizes: [2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-163-ed27a1ebda9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (3) must match the existing size (2) at non-singleton dimension 1.  Target sizes: [4, 3].  Tensor sizes: [2]"
     ]
    }
   ],
   "source": [
    "x.expand_as(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dimension이 다르지만 확장 규격이 1로 생각하고 작동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3268, 0.4271, 0.0936])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1345, 0.2745, 0.2929],\n",
       "        [0.7050, 0.5366, 0.8102],\n",
       "        [0.6568, 0.8906, 0.4919],\n",
       "        [0.5044, 0.7277, 0.5602]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand(4, 3)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3268, 0.4271, 0.0936],\n",
       "        [0.3268, 0.4271, 0.0936],\n",
       "        [0.3268, 0.4271, 0.0936],\n",
       "        [0.3268, 0.4271, 0.0936]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.expand_as(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.expand_as(y).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 보통의 경우 확장할 dim이 1이어야 확장이 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7446],\n",
       "         [0.7955],\n",
       "         [0.7044],\n",
       "         [0.6244]]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 4, 1)\n",
    "y = torch.rand(3, 4, 5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7446, 0.7446, 0.7446, 0.7446, 0.7446],\n",
       "         [0.7955, 0.7955, 0.7955, 0.7955, 0.7955],\n",
       "         [0.7044, 0.7044, 0.7044, 0.7044, 0.7044],\n",
       "         [0.6244, 0.6244, 0.6244, 0.6244, 0.6244]],\n",
       "\n",
       "        [[0.7446, 0.7446, 0.7446, 0.7446, 0.7446],\n",
       "         [0.7955, 0.7955, 0.7955, 0.7955, 0.7955],\n",
       "         [0.7044, 0.7044, 0.7044, 0.7044, 0.7044],\n",
       "         [0.6244, 0.6244, 0.6244, 0.6244, 0.6244]],\n",
       "\n",
       "        [[0.7446, 0.7446, 0.7446, 0.7446, 0.7446],\n",
       "         [0.7955, 0.7955, 0.7955, 0.7955, 0.7955],\n",
       "         [0.7044, 0.7044, 0.7044, 0.7044, 0.7044],\n",
       "         [0.6244, 0.6244, 0.6244, 0.6244, 0.6244]]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.expand_as(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.zeros_like(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### input tensor의 규격과 같고 각 요소가 0인 텐서 객체를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6619, 0.8975, 0.3214],\n",
       "        [0.6543, 0.2491, 0.5895]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.zeros_like(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.ones_like(x)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Linear(input, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### layer 사이의 matrix를 형성하는 기능\n",
    "#### ex) input size: [32, 512, 768], output size: [32, 512, 768]\n",
    "#### middle state matrix size: [32, 768, 768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "class example_linear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(example_linear, self).__init__()\n",
    "        self.num_attention_heads = 12\n",
    "        self.attention_head_size = 64\n",
    "        self.all_head_size = 768\n",
    "        \n",
    "        self.query = nn.Linear(768, self.all_head_size)\n",
    "        self.key = nn.Linear(768, self.all_head_size)\n",
    "        self.value = nn.Linear(768, self.all_head_size)\n",
    "        \n",
    "    def transpose_for_scores(self, x):\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
    "        x = x.view(*new_x_shape)\n",
    "        print('transpose view shape: \\t\\t', x.size())\n",
    "        print('transpose permute shape: \\t', x.permute(0, 2, 1, 3).size())\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "    \n",
    "    def forward(self, hidden_states):\n",
    "        print('input shape: \\t\\t', hidden_states.size())\n",
    "        mixed_query_layer = self.query(hidden_states)\n",
    "        print('mixed_query_layer shape: \\t', mixed_query_layer.size())\n",
    "        mixed_key_layer = self.key(hidden_states)\n",
    "        mixed_value_layer = self.value(hidden_states)\n",
    "\n",
    "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
    "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
    "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
    "        \n",
    "        print('query_layer shape: \\t', query_layer.size())\n",
    "        print('key_layer transpose shape: \\t', key_layer.transpose(-1, -2).size())\n",
    "        \n",
    "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "        print('attention_scores shpae: \\t', attention_scores.size())\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "        \n",
    "        # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
    "        attention_scores = attention_scores #+ attention_mask\n",
    "\n",
    "        # Normalize the attention scores to probabilities.\n",
    "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
    "        print('attention_probs shape: \\t', attention_probs.size())\n",
    "        \n",
    "        # This is actually dropping out entire tokens to attend to, which might\n",
    "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
    "#         attention_probs = self.dropout(attention_probs)\n",
    "        print('value_layer shape: \\t', value_layer.size())\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "        print('context_layer before permute shape: \\t', context_layer.size())\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        print('context_layer after permute shape: \\t', context_layer.size())\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)\n",
    "        \n",
    "        return context_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "single = torch.randn(32, 512, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: \t\t torch.Size([32, 512, 768])\n",
      "mixed_query_layer shape: \t torch.Size([32, 512, 768])\n",
      "transpose view shape: \t\t torch.Size([32, 512, 12, 64])\n",
      "transpose permute shape: \t torch.Size([32, 12, 512, 64])\n",
      "transpose view shape: \t\t torch.Size([32, 512, 12, 64])\n",
      "transpose permute shape: \t torch.Size([32, 12, 512, 64])\n",
      "transpose view shape: \t\t torch.Size([32, 512, 12, 64])\n",
      "transpose permute shape: \t torch.Size([32, 12, 512, 64])\n",
      "query_layer shape: \t torch.Size([32, 12, 512, 64])\n",
      "key_layer transpose shape: \t torch.Size([32, 12, 64, 512])\n",
      "attention_scores shpae: \t torch.Size([32, 12, 512, 512])\n",
      "attention_probs shape: \t torch.Size([32, 12, 512, 512])\n",
      "value_layer shape: \t torch.Size([32, 12, 512, 64])\n",
      "context_layer before permute shape: \t torch.Size([32, 12, 512, 64])\n",
      "context_layer after permute shape: \t torch.Size([32, 512, 12, 64])\n"
     ]
    }
   ],
   "source": [
    "att = example_linear()\n",
    "out = att(single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512, 768])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor.permute(dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### permute는 원소의 순서를 보존한다는 점에서 view와 다름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0,  1,  2,  3],\n",
       "          [ 4,  5,  6,  7],\n",
       "          [ 8,  9, 10, 11]],\n",
       "\n",
       "         [[12, 13, 14, 15],\n",
       "          [16, 17, 18, 19],\n",
       "          [20, 21, 22, 23]]]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(24).view(1, 2, 3, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0,  1,  2,  3],\n",
       "          [ 4,  5,  6,  7]],\n",
       "\n",
       "         [[ 8,  9, 10, 11],\n",
       "          [12, 13, 14, 15]],\n",
       "\n",
       "         [[16, 17, 18, 19],\n",
       "          [20, 21, 22, 23]]]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.view(1, 3, 2 ,4)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0,  1,  2,  3],\n",
       "          [12, 13, 14, 15]],\n",
       "\n",
       "         [[ 4,  5,  6,  7],\n",
       "          [16, 17, 18, 19]],\n",
       "\n",
       "         [[ 8,  9, 10, 11],\n",
       "          [20, 21, 22, 23]]]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.permute(0, 2, 1, 3)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor.contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정확한 기능을 모르겠음... 후에 누군가 추가 해주면 좋겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0,  1,  2,  3],\n",
       "          [12, 13, 14, 15]],\n",
       "\n",
       "         [[ 4,  5,  6,  7],\n",
       "          [16, 17, 18, 19]],\n",
       "\n",
       "         [[ 8,  9, 10, 11],\n",
       "          [20, 21, 22, 23]]]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = x.permute(0, 2, 1, 3).contiguous()\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Softmax(dim=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 선택한 dimension에 softmax를 취한 텐서 객체 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1389, -0.1301,  0.4512],\n",
       "        [ 0.4560,  0.6331, -0.1089],\n",
       "        [ 0.9279, -0.8859,  0.5154],\n",
       "        [-1.1721,  1.4257, -2.1610]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\anaconda36\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.3194, 0.2441, 0.4365],\n",
       "        [0.3620, 0.4322, 0.2058],\n",
       "        [0.5479, 0.0893, 0.3627],\n",
       "        [0.0675, 0.9073, 0.0251]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax()\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2064, 0.1197, 0.3689],\n",
       "        [0.2835, 0.2568, 0.2107],\n",
       "        [0.4544, 0.0562, 0.3934],\n",
       "        [0.0556, 0.5673, 0.0271]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=0)\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3194, 0.2441, 0.4365],\n",
       "        [0.3620, 0.4322, 0.2058],\n",
       "        [0.5479, 0.0893, 0.3627],\n",
       "        [0.0675, 0.9073, 0.0251]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3194, 0.2441, 0.4365],\n",
       "        [0.3620, 0.4322, 0.2058],\n",
       "        [0.5479, 0.0893, 0.3627],\n",
       "        [0.0675, 0.9073, 0.0251]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=-1)\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3194, 0.2441, 0.4365],\n",
       "        [0.3620, 0.4322, 0.2058],\n",
       "        [0.5479, 0.0893, 0.3627],\n",
       "        [0.0675, 0.9073, 0.0251]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Softmax(dim=-1)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.ModuleList(modules=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### submodule 을 list에 담는 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testModuleList(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(testModuleList, self).__init__()\n",
    "        self.layers = nn.ModuleList(nn.Linear(5, 5) for _ in range(10))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = F.relu(layer(x))\n",
    "            print('{}'.format(i), end='\\t')\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5448, -0.2920,  0.7299,  0.8775, -0.4369],\n",
       "        [ 0.4264, -0.1957,  0.8240,  0.2185,  0.2184],\n",
       "        [ 0.1578,  0.6535,  0.2172,  0.2155, -0.4410]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t1\t2\t3\t4\t5\t6\t7\t8\t9\t"
     ]
    }
   ],
   "source": [
    "net = testModuleList()\n",
    "out = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2128, 0.1179, 0.0000, 0.0000, 0.3976],\n",
       "        [0.2129, 0.1179, 0.0000, 0.0000, 0.3976],\n",
       "        [0.2129, 0.1179, 0.0000, 0.0000, 0.3976]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## isinstance(객체, 자료형)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 객체가 자료형과 맞는지 여부를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(1, int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance('hi', str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myList = []\n",
    "isinstance(myList, list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 클래스 객체 여부도 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myClass:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testClass = myClass()\n",
    "isinstance(testClass, myClass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor.to(device=None, dtype=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensor의 device혹은 data type을 바꾸고 싶을 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2508, 0.7258, 0.2338],\n",
       "        [0.1036, 0.5457, 0.9753]])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones(2, 3)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4087, 0.6687, 0.6007],\n",
       "        [0.1189, 0.8963, 0.2887]], dtype=torch.float64)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2, 3, dtype=torch.double)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.to(dtype=x.dtype)\n",
    "y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iter & next method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iter() 로 iterator 객체 형태 반환\n",
    "#### next() method로 객체의 처음부터 하나씩 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n"
     ]
    }
   ],
   "source": [
    "x = iter(['a', 'b', 'c'])\n",
    "y = next(x)\n",
    "print(y)\n",
    "y = next(x)\n",
    "print(y)\n",
    "y = next(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "<list_iterator object at 0x000001CE4D34DCF8>\n",
      "b\n",
      "<list_iterator object at 0x000001CE4D34DCF8>\n"
     ]
    }
   ],
   "source": [
    "x = iter(['a', 'b', 'c'])\n",
    "y = next(x)\n",
    "print(y)\n",
    "print(x)\n",
    "y = next(x)\n",
    "print(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 마지막 요소를 지나서면 에러 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-203-92de4e9f6b1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class NN.parameter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 신경망 객체에 선언된 parameters 를 가져오는 method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "#         test = torch.ones(3, 4)\n",
    "        print(self.parameter())\n",
    "        \n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        \n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        print('conv2 > max_pooling 후의 x shpae\\t', x.size())\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        print('after reshape of x\\t', x.size())\n",
    "        x = F.relu(self.fc1(x))\n",
    "        print('after linear function\\t', x.size())\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        \n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Variable(torch.randn(1, 1, 32, 32), \n",
    "                requires_grad=True) # nSample, nChannel, Height, Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None torch.Size([6, 1, 5, 5])\n",
      "None torch.Size([6])\n",
      "None torch.Size([16, 6, 5, 5])\n",
      "None torch.Size([16])\n",
      "None torch.Size([120, 400])\n",
      "None torch.Size([120])\n",
      "None torch.Size([84, 120])\n",
      "None torch.Size([84])\n",
      "None torch.Size([10, 84])\n",
      "None torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in net.parameters():\n",
    "    print(p.name, p.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class NN.named_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 신경망의 parameter를 (이름, 데이터 값) tuple 형태로 반환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "Parameter containing:\n",
      "tensor([[[[-1.3551e-02,  7.1723e-02,  1.3095e-01, -1.7946e-01, -1.9144e-01],\n",
      "          [-6.3771e-02,  5.0846e-02, -1.6471e-01, -1.5248e-01, -1.9750e-01],\n",
      "          [ 1.7952e-01,  9.8860e-03, -4.5322e-02, -7.7297e-03,  5.0834e-02],\n",
      "          [ 1.4284e-01, -6.8309e-02, -1.1847e-01,  1.3641e-01,  1.9590e-01],\n",
      "          [ 1.7032e-01,  6.5213e-02,  8.5182e-02,  5.6357e-02,  1.7980e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.1066e-02, -1.3164e-01, -1.0162e-01,  1.3573e-01,  5.5445e-02],\n",
      "          [-6.8366e-02, -1.5092e-01, -2.4752e-03, -3.5418e-03,  1.6175e-01],\n",
      "          [ 4.9975e-02, -1.0374e-01,  1.4506e-01, -9.8533e-02,  1.1970e-01],\n",
      "          [-1.6559e-01,  1.6889e-01, -5.4293e-02,  9.1411e-02, -1.4294e-01],\n",
      "          [-1.3175e-01, -8.1450e-02, -1.3395e-02,  4.7471e-02,  1.0807e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.5364e-02, -8.2596e-02,  5.4527e-02, -1.6190e-01,  1.3557e-01],\n",
      "          [-1.2136e-04, -1.3412e-01, -1.2526e-01, -7.2968e-02,  1.0480e-01],\n",
      "          [ 4.9474e-03,  1.9435e-02,  1.5984e-01,  1.4222e-01,  1.5758e-01],\n",
      "          [-2.2595e-02, -1.2741e-01,  1.4262e-01,  1.2594e-01, -6.9949e-02],\n",
      "          [ 7.4408e-02,  1.0627e-01,  1.7866e-01, -1.5469e-01, -7.4779e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7682e-02,  2.1636e-02,  1.7551e-01,  1.4654e-01,  5.6046e-02],\n",
      "          [ 7.7519e-02,  1.6515e-02,  1.6059e-01,  1.4803e-01,  1.8672e-01],\n",
      "          [-1.6514e-01,  1.8463e-01, -7.4569e-02, -9.4933e-02,  1.0967e-01],\n",
      "          [-1.7592e-01, -1.0182e-01, -5.1844e-02, -7.6537e-02, -1.7458e-02],\n",
      "          [-9.7663e-02, -1.4829e-01, -7.1746e-02, -9.3615e-02,  1.5898e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5539e-01, -1.6196e-01, -7.6788e-02, -1.8198e-01, -6.7547e-02],\n",
      "          [-1.7761e-02,  1.4172e-01,  3.0540e-02, -1.1003e-01, -4.1229e-02],\n",
      "          [ 1.1739e-01, -1.7746e-01,  5.5547e-02, -9.2608e-02,  1.1018e-01],\n",
      "          [ 1.3827e-01,  6.6980e-02,  7.4876e-02,  1.7342e-01,  1.9389e-01],\n",
      "          [ 1.7264e-01, -1.5125e-01, -1.0727e-01, -9.0587e-02,  3.5627e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8747e-01,  1.4388e-01, -4.8587e-04, -1.6511e-02,  1.2899e-01],\n",
      "          [ 1.4788e-02,  1.7315e-01,  6.4228e-02,  9.2043e-02, -8.7797e-02],\n",
      "          [ 1.4056e-01, -1.1609e-01,  1.3362e-01,  1.8605e-01, -4.2717e-02],\n",
      "          [-3.6386e-02, -1.5192e-01, -1.7254e-01,  1.5087e-01,  1.4686e-02],\n",
      "          [ 1.5140e-01, -1.1511e-01,  3.2004e-02, -7.9017e-02,  5.8165e-02]]]],\n",
      "       requires_grad=True)\n",
      "conv1.bias\n",
      "Parameter containing:\n",
      "tensor([ 0.0020, -0.0019, -0.1359,  0.0299, -0.1280, -0.1242],\n",
      "       requires_grad=True)\n",
      "conv2.weight\n",
      "Parameter containing:\n",
      "tensor([[[[ 6.2388e-02, -5.7742e-02, -8.1258e-02,  4.3874e-02, -5.4451e-02],\n",
      "          [ 2.4633e-02,  1.3621e-02, -3.8918e-02,  7.4136e-03, -7.0569e-04],\n",
      "          [ 4.7172e-02, -7.7290e-02,  6.6885e-02, -8.1057e-02,  3.7612e-02],\n",
      "          [-7.0277e-02, -7.4744e-02, -5.8966e-02, -1.5464e-02, -5.3663e-02],\n",
      "          [ 5.3934e-02,  1.2848e-03,  1.7805e-02,  8.0592e-02,  6.5491e-02]],\n",
      "\n",
      "         [[ 5.2751e-03,  5.2791e-03, -3.5561e-03,  4.2472e-02,  6.3408e-02],\n",
      "          [ 7.2715e-02, -1.2413e-02, -2.8806e-02,  7.9662e-02, -7.1534e-02],\n",
      "          [ 3.6635e-03,  3.4118e-02, -4.6710e-02, -1.6963e-02, -5.5685e-02],\n",
      "          [ 5.1969e-02, -4.1458e-02,  4.8944e-02,  2.9057e-02,  7.8767e-02],\n",
      "          [ 5.8731e-02,  1.5743e-02, -4.7967e-02,  3.4909e-02, -4.0660e-02]],\n",
      "\n",
      "         [[ 1.9414e-03,  3.7159e-02,  3.2136e-02, -5.7980e-02, -7.0120e-02],\n",
      "          [ 4.8349e-02, -7.8386e-02, -6.9015e-02, -2.3768e-02, -6.0622e-02],\n",
      "          [ 1.9612e-02,  7.6866e-02, -1.6298e-02, -7.2721e-02,  4.4023e-02],\n",
      "          [ 2.5518e-03, -4.2705e-02, -3.1113e-02,  5.0266e-02,  2.6984e-02],\n",
      "          [ 2.5590e-02, -7.6565e-02, -3.4492e-02,  2.2703e-02,  2.1547e-02]],\n",
      "\n",
      "         [[-5.2363e-05, -2.7185e-02, -1.6272e-02, -6.1310e-02, -3.4509e-02],\n",
      "          [ 6.1927e-04, -3.0052e-02,  2.5932e-02, -5.0579e-02,  2.1714e-02],\n",
      "          [-5.7533e-02, -3.5440e-02,  7.3799e-02, -6.9738e-02, -5.4493e-03],\n",
      "          [-3.3244e-02,  3.9866e-02, -6.5730e-02,  4.0080e-03, -6.3943e-02],\n",
      "          [-3.8805e-02,  6.7640e-02,  3.1853e-02,  1.1752e-03,  4.5375e-02]],\n",
      "\n",
      "         [[-2.0894e-02,  5.4517e-02,  8.1621e-02,  7.0975e-03,  4.9515e-02],\n",
      "          [-3.3716e-02, -3.2237e-02,  5.6568e-02, -4.1122e-02,  2.0643e-02],\n",
      "          [ 1.2271e-02, -1.6613e-02, -4.6177e-03, -4.1395e-04,  2.5261e-02],\n",
      "          [-5.5114e-02, -2.9068e-02,  3.0954e-02, -1.5218e-02,  1.4479e-02],\n",
      "          [-6.6128e-02,  7.3331e-02,  8.1203e-02,  1.9015e-02,  6.9719e-02]],\n",
      "\n",
      "         [[ 5.9821e-02,  5.9611e-02, -5.8235e-02, -4.1666e-02,  1.6417e-02],\n",
      "          [-7.5853e-02,  4.2406e-02, -3.1872e-02, -2.0016e-02,  6.9476e-02],\n",
      "          [ 2.6793e-02, -5.9271e-02, -1.1908e-02,  3.9124e-02,  4.8907e-02],\n",
      "          [ 2.0887e-02, -5.3211e-02,  7.8924e-02, -6.1370e-02,  3.7245e-02],\n",
      "          [ 4.6207e-02,  6.7378e-02, -3.7825e-02, -4.7611e-02, -2.4376e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8868e-02,  5.1925e-02,  2.7584e-02,  4.5272e-02,  7.6485e-03],\n",
      "          [-6.6399e-02,  8.1284e-02,  1.2940e-02, -8.8542e-03,  5.0375e-02],\n",
      "          [ 2.0407e-02, -4.3311e-02,  1.2219e-02,  5.7694e-02,  5.9360e-02],\n",
      "          [-2.3577e-02,  1.9204e-02, -3.2978e-02,  1.9627e-03, -4.6947e-02],\n",
      "          [-5.2870e-02,  4.5329e-02, -1.0780e-02, -3.7516e-03,  2.4789e-02]],\n",
      "\n",
      "         [[-4.8989e-02, -1.6979e-02,  7.4063e-02, -4.4738e-02, -4.1345e-02],\n",
      "          [ 2.4057e-02,  7.8927e-02, -7.5880e-02,  1.0396e-02, -7.0526e-02],\n",
      "          [ 5.6404e-03, -6.4327e-02,  3.2865e-02, -4.9885e-02,  3.6337e-02],\n",
      "          [ 3.7183e-02,  7.0283e-03, -5.7778e-02, -5.8387e-02, -4.7943e-02],\n",
      "          [ 6.3855e-02, -3.1289e-03,  3.8303e-03,  7.0262e-02,  6.2704e-03]],\n",
      "\n",
      "         [[-6.4403e-02,  3.2793e-02, -7.8985e-02, -1.8421e-02,  7.2924e-03],\n",
      "          [ 6.1709e-02, -5.8900e-02,  1.8790e-02, -6.1457e-02, -7.7264e-02],\n",
      "          [-3.4879e-02,  7.0751e-02, -4.7332e-03,  6.8165e-03,  5.5482e-02],\n",
      "          [-7.7527e-02,  4.2268e-02,  5.6691e-02,  1.0009e-02, -4.9628e-02],\n",
      "          [ 4.4891e-02, -5.1613e-02,  4.8766e-02,  5.1724e-02, -1.5341e-03]],\n",
      "\n",
      "         [[ 4.4373e-02,  7.1716e-02,  2.2899e-02,  4.2696e-02,  1.0046e-02],\n",
      "          [-7.6665e-02, -4.5002e-03,  4.5349e-02,  1.2300e-02, -2.2023e-02],\n",
      "          [-6.8020e-02, -5.0667e-02,  2.6992e-02,  6.5590e-02,  4.6417e-02],\n",
      "          [-1.7409e-02,  4.8760e-02, -6.1562e-02, -6.5563e-02,  3.6771e-02],\n",
      "          [ 7.4924e-02, -6.0831e-02,  2.2871e-02,  1.4960e-02,  1.6196e-03]],\n",
      "\n",
      "         [[-5.5987e-03,  1.5725e-02,  4.5778e-02,  2.6192e-02,  4.9862e-04],\n",
      "          [ 5.8044e-02, -7.8546e-02,  5.0620e-02,  3.9225e-02, -4.4774e-02],\n",
      "          [ 7.9432e-02,  3.0863e-02,  3.9329e-03, -5.6261e-02, -1.4348e-02],\n",
      "          [-1.0625e-02, -4.2326e-02,  2.8160e-02, -1.1206e-02, -7.8877e-02],\n",
      "          [-6.9844e-02,  6.8339e-02,  5.7921e-02, -7.7220e-02, -4.0788e-02]],\n",
      "\n",
      "         [[-2.2388e-02, -7.1533e-02,  4.5186e-02, -7.8773e-02, -5.0850e-02],\n",
      "          [-3.9795e-02,  2.1884e-02,  2.7676e-02, -6.0629e-02,  6.2120e-02],\n",
      "          [-5.5790e-02, -6.0689e-02, -7.6685e-02,  5.4283e-02, -2.0017e-04],\n",
      "          [-7.7355e-02, -3.7417e-03,  1.9103e-02, -5.9867e-02,  1.3416e-03],\n",
      "          [-5.7789e-02, -7.6180e-02, -3.3640e-02, -3.6040e-02, -4.9723e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1371e-02,  6.7236e-02,  8.8133e-04,  6.6290e-02, -4.4047e-02],\n",
      "          [ 5.7861e-02,  4.8886e-02,  4.1892e-02, -1.6675e-02,  7.9339e-02],\n",
      "          [ 7.2640e-02,  7.4117e-02,  1.5753e-02, -1.8924e-02, -1.4422e-02],\n",
      "          [-4.8292e-02, -2.8332e-02, -1.7221e-02,  3.3780e-03, -6.2761e-02],\n",
      "          [-4.9448e-02, -5.2144e-02, -5.5276e-02, -4.5957e-02,  2.0914e-02]],\n",
      "\n",
      "         [[ 2.6746e-02,  2.4999e-02, -5.2206e-02,  1.4351e-02,  2.6128e-02],\n",
      "          [ 8.0601e-02, -5.0054e-02,  4.8877e-02, -9.6583e-03, -2.1569e-02],\n",
      "          [-3.3767e-03, -1.9156e-02, -1.4162e-02, -5.9559e-02,  7.3462e-02],\n",
      "          [-7.5718e-03,  1.7027e-02,  1.9158e-02,  3.8850e-02,  3.7180e-04],\n",
      "          [ 6.5527e-02, -4.2087e-02, -7.4974e-02, -1.6090e-02, -2.7393e-02]],\n",
      "\n",
      "         [[-2.5039e-02,  3.9385e-02, -5.6949e-02, -4.7286e-02,  5.9374e-02],\n",
      "          [ 3.7656e-02,  3.4946e-02,  3.8991e-02,  5.9154e-02, -3.9949e-02],\n",
      "          [ 7.1003e-04,  6.0594e-02, -5.6692e-02,  1.7455e-02,  1.8726e-02],\n",
      "          [ 7.2458e-02, -4.3027e-02,  5.2253e-03, -5.5769e-03,  5.6157e-02],\n",
      "          [-5.1067e-02,  7.4239e-03,  2.0447e-02, -3.2877e-02,  7.8354e-02]],\n",
      "\n",
      "         [[ 7.3107e-02,  3.4143e-02, -1.5369e-02,  3.8216e-02, -1.8360e-02],\n",
      "          [ 6.0878e-03,  6.4037e-02,  4.0642e-02, -4.3850e-02, -4.4012e-02],\n",
      "          [-8.0210e-02,  1.0018e-02, -2.0202e-02,  5.2501e-02,  7.1582e-02],\n",
      "          [-5.1250e-02,  5.6137e-02,  5.2230e-03, -5.2213e-02,  3.1062e-02],\n",
      "          [ 1.4594e-02,  3.4032e-02,  2.5432e-02, -3.3831e-02, -4.5172e-02]],\n",
      "\n",
      "         [[-1.2760e-02,  1.4487e-02,  4.0919e-02,  1.0664e-02,  7.0154e-02],\n",
      "          [ 7.9861e-02, -5.7895e-03,  5.4381e-03, -4.7168e-02, -7.0959e-02],\n",
      "          [-7.5665e-02,  3.1124e-02,  5.3526e-02,  2.1929e-02,  5.1410e-02],\n",
      "          [ 1.3074e-02, -7.7517e-02, -4.2898e-02, -5.6892e-02,  4.5084e-02],\n",
      "          [-5.1147e-02, -2.5216e-02,  4.1506e-02,  5.2050e-02,  3.7649e-02]],\n",
      "\n",
      "         [[ 3.4241e-02,  4.7032e-02,  2.7360e-02, -1.2098e-02,  4.7579e-02],\n",
      "          [ 6.5744e-02,  6.0748e-02,  5.3529e-03, -2.5687e-03,  4.9145e-02],\n",
      "          [-4.0882e-02,  5.0674e-02,  7.8843e-02, -4.3159e-02, -2.3994e-02],\n",
      "          [ 7.9138e-03, -3.5855e-02, -1.8193e-02, -5.6604e-02,  3.1877e-02],\n",
      "          [ 1.1459e-02,  6.0919e-02,  1.9484e-02, -7.4893e-02,  6.9911e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.0218e-02,  2.5560e-02, -1.0720e-02, -6.7009e-03, -2.3685e-02],\n",
      "          [ 7.1588e-02, -1.7095e-03,  3.4315e-02,  3.4113e-02,  7.5604e-02],\n",
      "          [-1.3453e-02, -1.2766e-02, -1.9406e-02,  7.8683e-02,  3.8064e-02],\n",
      "          [-3.7886e-02,  1.0154e-02, -7.2926e-02, -6.7341e-02,  7.4266e-03],\n",
      "          [-3.9049e-02, -5.7337e-02, -1.2963e-02,  3.3674e-02, -4.4310e-02]],\n",
      "\n",
      "         [[ 5.5976e-05,  5.1189e-02,  7.1062e-02,  1.0339e-02,  5.5518e-02],\n",
      "          [ 7.1274e-02, -6.4442e-02,  1.1934e-02, -5.0876e-02, -1.2736e-02],\n",
      "          [ 1.3026e-02,  2.4105e-02,  7.4351e-02,  2.3290e-02,  4.9559e-02],\n",
      "          [ 7.3799e-02,  7.8030e-02,  7.3405e-02, -2.9665e-02,  5.5259e-02],\n",
      "          [-8.0227e-02, -5.5711e-02,  6.1129e-02, -5.4755e-02, -1.1816e-02]],\n",
      "\n",
      "         [[-5.0499e-03, -6.5101e-02,  6.2491e-02,  6.6943e-02,  4.2320e-02],\n",
      "          [-2.4099e-02,  7.5993e-03,  3.1334e-02,  5.6737e-02,  4.7858e-03],\n",
      "          [ 8.1055e-02, -7.6626e-02,  6.3851e-02,  6.8584e-02, -3.4514e-02],\n",
      "          [ 7.6334e-02,  6.5564e-02,  2.5565e-02, -1.9234e-02, -4.8283e-02],\n",
      "          [ 8.0970e-02, -6.7799e-02,  4.6198e-02,  2.2371e-02,  5.3582e-02]],\n",
      "\n",
      "         [[ 6.8644e-02, -4.3321e-02,  4.1193e-02, -1.7194e-02, -5.2951e-02],\n",
      "          [ 1.4715e-02, -2.4797e-02,  7.7257e-02,  9.4752e-03,  3.0012e-02],\n",
      "          [-7.5344e-02, -3.9113e-02,  7.9062e-03, -6.5991e-02,  2.9762e-02],\n",
      "          [-7.0060e-02, -7.5607e-02, -6.5714e-02,  1.6257e-02, -6.5840e-02],\n",
      "          [-4.6129e-02,  4.7077e-02, -2.2475e-04,  1.2058e-02,  7.8171e-02]],\n",
      "\n",
      "         [[-4.6358e-02, -4.6426e-02, -7.1868e-02, -1.5023e-03, -8.7540e-03],\n",
      "          [ 7.2422e-02, -4.3064e-02,  2.0765e-02,  5.3919e-02, -1.2264e-02],\n",
      "          [-7.2785e-02, -4.4641e-02,  8.1247e-02,  6.2205e-02, -8.0370e-02],\n",
      "          [-3.8693e-02, -3.9175e-03, -7.9058e-02, -5.5737e-02,  7.7572e-02],\n",
      "          [-6.8030e-02, -1.5558e-02,  5.3432e-02,  5.9307e-02,  3.4125e-02]],\n",
      "\n",
      "         [[ 7.7774e-02,  4.0886e-02,  1.7920e-04,  4.5547e-02,  6.1421e-02],\n",
      "          [ 3.7489e-02,  7.2195e-02,  7.4833e-02,  1.9301e-02,  1.9289e-02],\n",
      "          [-4.2094e-02, -5.1962e-03,  1.1599e-02,  1.1465e-02,  5.0151e-02],\n",
      "          [-7.7789e-02, -6.8736e-02,  3.2972e-02,  2.1256e-02,  4.3607e-02],\n",
      "          [ 5.0946e-02, -4.8660e-02, -1.1221e-02, -4.4236e-02,  1.4835e-03]]],\n",
      "\n",
      "\n",
      "        [[[-7.8765e-02, -3.9791e-02, -6.6161e-02,  3.9552e-02,  8.2665e-03],\n",
      "          [ 8.0635e-03,  6.3008e-02, -6.6789e-02,  9.7459e-03, -2.4606e-02],\n",
      "          [ 6.4617e-02,  5.9083e-02,  6.9399e-02,  5.1702e-02,  6.1535e-02],\n",
      "          [-4.0383e-02, -5.9128e-02,  3.2127e-02, -6.2940e-02,  7.8938e-02],\n",
      "          [-3.3663e-02,  5.9935e-02, -6.9492e-02, -7.7271e-02, -2.7223e-02]],\n",
      "\n",
      "         [[ 9.2199e-03,  2.1181e-02, -6.0441e-02, -6.7574e-02, -3.5139e-02],\n",
      "          [ 6.2278e-02, -7.8074e-02,  7.2163e-02,  3.3903e-02,  4.1467e-02],\n",
      "          [-5.5489e-02,  2.1234e-02, -6.3362e-02,  5.8958e-02,  3.1462e-02],\n",
      "          [ 2.0472e-02, -3.1244e-02, -7.6267e-02, -3.8371e-02, -4.4264e-02],\n",
      "          [-7.9959e-02, -2.2301e-02, -6.5602e-02, -7.4358e-02, -4.3536e-02]],\n",
      "\n",
      "         [[-7.5628e-02, -6.2658e-02,  7.2963e-02, -4.9658e-02, -7.3606e-03],\n",
      "          [ 5.0587e-02, -7.3952e-02,  6.3014e-02, -7.6996e-02,  5.5979e-02],\n",
      "          [-6.1459e-02,  4.2251e-02, -2.1445e-02,  1.1128e-02,  4.4446e-02],\n",
      "          [-4.4960e-03, -2.3184e-02, -6.9035e-02, -5.3340e-02,  6.0576e-02],\n",
      "          [ 2.8313e-02,  7.5711e-02,  7.0907e-02,  7.7681e-02,  3.9014e-02]],\n",
      "\n",
      "         [[-7.6462e-02, -3.0594e-02,  7.8554e-02, -5.2791e-02,  7.1681e-02],\n",
      "          [-3.3717e-02,  1.7878e-02,  4.8156e-02,  4.0692e-02, -6.4831e-02],\n",
      "          [-3.5947e-02,  6.8471e-02,  7.8086e-02, -8.0733e-02, -7.8163e-03],\n",
      "          [ 3.7935e-02, -3.4607e-02, -1.4612e-02,  1.2097e-02,  2.0431e-02],\n",
      "          [-2.7819e-02,  5.4359e-02,  2.6460e-02, -4.0747e-02,  3.9084e-02]],\n",
      "\n",
      "         [[ 2.5791e-02, -1.1047e-02,  3.2072e-02,  3.9812e-02,  2.9567e-02],\n",
      "          [-2.7046e-03, -4.3643e-02,  2.8720e-02,  6.3131e-02, -3.8804e-02],\n",
      "          [ 4.3588e-03, -2.8038e-02, -1.6792e-02,  6.1972e-02, -7.4074e-02],\n",
      "          [-4.6524e-02,  6.1631e-02, -1.5403e-02, -1.6055e-02,  1.3822e-04],\n",
      "          [-1.8322e-02,  3.2871e-03, -8.0853e-02,  4.5294e-02, -1.4215e-02]],\n",
      "\n",
      "         [[ 2.5083e-02,  3.4168e-03,  4.4071e-02, -3.9614e-02,  3.1767e-03],\n",
      "          [ 1.1387e-02, -8.4593e-03, -1.7398e-02,  4.6395e-02,  5.4873e-02],\n",
      "          [ 4.9443e-02, -1.7829e-02, -7.4968e-02,  4.9983e-02,  6.5203e-02],\n",
      "          [ 1.5224e-02, -1.2134e-02, -9.0199e-03,  1.0726e-02, -7.1686e-02],\n",
      "          [-8.9038e-03, -5.6103e-02, -6.1042e-02,  2.6286e-02,  5.1318e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.7627e-03, -6.1486e-03, -5.7750e-02,  1.7422e-02,  6.8028e-02],\n",
      "          [ 6.2087e-02, -4.0918e-02, -7.4711e-02, -2.4138e-02,  5.0443e-02],\n",
      "          [ 5.4089e-02, -5.2240e-03, -3.4530e-03,  6.6672e-02, -6.5896e-02],\n",
      "          [-2.7205e-02, -7.6944e-02,  7.1493e-02,  8.7818e-03,  4.1129e-02],\n",
      "          [-6.2804e-02,  6.3655e-02, -4.8569e-03, -4.4751e-02,  3.4504e-02]],\n",
      "\n",
      "         [[ 5.9677e-02,  3.0008e-02,  4.0841e-02, -7.6502e-02, -5.3625e-03],\n",
      "          [ 1.3891e-02, -3.0525e-02, -2.9137e-02, -7.0508e-02,  5.1463e-02],\n",
      "          [ 7.6042e-02,  7.3930e-02,  2.8800e-02, -2.9757e-02, -1.0615e-02],\n",
      "          [ 6.7333e-02, -6.0740e-02, -1.7407e-02, -3.7994e-02,  1.1230e-02],\n",
      "          [-1.8024e-02,  2.8403e-02,  5.6754e-02, -8.7368e-03,  7.0222e-02]],\n",
      "\n",
      "         [[ 2.5386e-02, -4.2424e-02,  5.6245e-02, -7.7386e-02, -2.4336e-02],\n",
      "          [-2.0159e-02,  2.2408e-02,  5.3645e-02,  3.9935e-03, -7.1652e-02],\n",
      "          [ 3.6478e-02, -6.9837e-02, -1.8387e-02, -1.8801e-02, -1.0053e-02],\n",
      "          [-3.2289e-02,  7.8720e-03, -5.2536e-03,  8.1032e-02,  7.3132e-02],\n",
      "          [ 1.9345e-02,  5.0137e-02,  3.1808e-02,  5.0663e-02, -2.4806e-02]],\n",
      "\n",
      "         [[ 3.4760e-02, -4.0007e-02,  2.0400e-02, -8.8195e-03,  2.9926e-02],\n",
      "          [ 4.6972e-02, -3.0200e-02, -4.8686e-02, -5.3065e-02,  7.3031e-03],\n",
      "          [ 6.9076e-02, -1.2354e-02, -5.2642e-02,  1.7133e-02, -2.6328e-02],\n",
      "          [ 4.0799e-02, -4.1519e-02, -1.7737e-02,  1.6382e-02,  2.6203e-02],\n",
      "          [ 3.5796e-02,  3.5794e-02,  4.8140e-02, -8.1961e-04,  4.2458e-02]],\n",
      "\n",
      "         [[-6.8238e-02, -6.9025e-02,  4.7482e-03,  7.3519e-02,  7.5495e-02],\n",
      "          [ 5.4546e-02,  6.5603e-02, -3.8515e-02,  7.4906e-02, -2.6983e-02],\n",
      "          [-2.5544e-02, -5.9059e-02,  2.4360e-02, -7.6712e-02,  1.2380e-02],\n",
      "          [-1.4863e-02,  2.0851e-02,  5.9859e-02,  6.7564e-03, -1.5764e-02],\n",
      "          [ 2.1338e-02,  4.7524e-02,  4.9039e-02,  2.1149e-02, -2.8334e-02]],\n",
      "\n",
      "         [[ 6.9081e-02,  1.1502e-04,  3.5654e-02,  2.7331e-02,  5.6357e-02],\n",
      "          [-6.6598e-02,  7.2702e-02,  6.5332e-02, -4.7132e-02, -4.8414e-02],\n",
      "          [ 2.9385e-02,  3.3404e-02, -5.2773e-02,  7.2581e-02,  2.0353e-02],\n",
      "          [ 4.9098e-02,  4.6153e-02, -4.9346e-02, -2.7710e-02, -7.0648e-02],\n",
      "          [ 7.2180e-02, -6.5519e-02,  5.4893e-02,  7.7036e-02, -2.8238e-03]]]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       requires_grad=True)\n",
      "conv2.bias\n",
      "Parameter containing:\n",
      "tensor([ 0.0326, -0.0050, -0.0077, -0.0480, -0.0015, -0.0358,  0.0006,  0.0553,\n",
      "        -0.0527,  0.0112, -0.0385,  0.0051, -0.0284,  0.0680, -0.0107, -0.0194],\n",
      "       requires_grad=True)\n",
      "fc1.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0262,  0.0459,  0.0487,  ...,  0.0470, -0.0373,  0.0406],\n",
      "        [ 0.0166,  0.0253,  0.0189,  ..., -0.0276, -0.0463,  0.0207],\n",
      "        [-0.0243, -0.0230, -0.0048,  ..., -0.0162,  0.0360, -0.0359],\n",
      "        ...,\n",
      "        [-0.0294, -0.0273,  0.0160,  ...,  0.0118,  0.0343,  0.0084],\n",
      "        [-0.0492,  0.0010, -0.0361,  ...,  0.0125, -0.0481,  0.0306],\n",
      "        [-0.0320, -0.0362,  0.0367,  ...,  0.0168,  0.0160, -0.0276]],\n",
      "       requires_grad=True)\n",
      "fc1.bias\n",
      "Parameter containing:\n",
      "tensor([-1.1413e-03,  2.4427e-02,  3.8341e-02,  4.7606e-03,  4.5988e-02,\n",
      "         1.7020e-02, -2.7459e-02, -2.4151e-02, -1.5629e-02, -2.2665e-02,\n",
      "        -1.2155e-02, -8.9984e-04,  5.1179e-03, -4.7015e-02, -3.4684e-03,\n",
      "        -2.1990e-02,  3.0660e-02,  2.5520e-02,  4.8762e-02,  2.4282e-02,\n",
      "         1.7471e-02,  1.0241e-02,  2.5144e-02, -2.6074e-02,  4.0754e-02,\n",
      "        -1.7979e-02, -3.3758e-02,  4.3393e-03,  1.8655e-02,  1.7936e-02,\n",
      "         4.6449e-02, -3.6720e-02, -3.9897e-02, -2.2971e-02, -1.9432e-03,\n",
      "         3.0631e-02, -1.7195e-02,  4.9405e-02, -2.8371e-02, -1.0181e-02,\n",
      "         2.6708e-02, -1.7302e-02,  2.0149e-02,  9.9513e-03,  1.4374e-02,\n",
      "         1.7098e-02, -2.2804e-02,  2.1031e-02,  8.1550e-03, -1.5895e-02,\n",
      "         4.8552e-02, -2.9610e-02,  2.1583e-02, -1.5638e-02, -6.3568e-05,\n",
      "         1.8033e-02,  1.6830e-03,  4.8829e-02, -3.3067e-02,  3.9524e-02,\n",
      "        -3.0372e-02, -3.8770e-02,  2.3559e-02, -9.0977e-03, -2.3638e-02,\n",
      "        -1.2855e-02, -4.6206e-02, -2.9211e-02, -2.4439e-02,  2.7972e-02,\n",
      "        -1.4096e-02, -1.5841e-02, -4.6331e-02, -7.1072e-03,  3.5300e-02,\n",
      "         2.1060e-02, -1.7801e-03, -5.3392e-03,  3.3152e-02, -4.9898e-02,\n",
      "        -7.6211e-03, -4.0877e-02,  1.7668e-03,  6.7020e-03,  3.5685e-02,\n",
      "         2.7788e-02, -2.9722e-02,  1.5060e-02,  2.6168e-02,  2.8907e-02,\n",
      "         5.6434e-03, -7.6622e-03,  2.7209e-02,  4.9688e-02, -3.8915e-02,\n",
      "        -4.4182e-03, -1.5976e-02,  5.3218e-03, -2.7987e-02,  1.6514e-02,\n",
      "         4.6769e-02, -2.8087e-03, -4.3887e-02,  7.2881e-03,  2.1903e-03,\n",
      "        -1.8216e-02,  2.2027e-02, -2.4372e-02,  4.2839e-02, -4.3885e-02,\n",
      "        -2.3755e-04, -2.2289e-02,  2.9833e-02,  3.9198e-02,  2.6660e-02,\n",
      "        -3.8172e-02, -3.7314e-02,  3.6375e-02, -7.3730e-03,  8.2334e-03],\n",
      "       requires_grad=True)\n",
      "fc2.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0112,  0.0599,  0.0462,  ..., -0.0274, -0.0230, -0.0150],\n",
      "        [-0.0534, -0.0723, -0.0798,  ..., -0.0443,  0.0266, -0.0747],\n",
      "        [ 0.0723,  0.0227,  0.0169,  ...,  0.0330,  0.0220, -0.0400],\n",
      "        ...,\n",
      "        [-0.0041,  0.0033,  0.0883,  ..., -0.0275, -0.0527, -0.0767],\n",
      "        [ 0.0451, -0.0433,  0.0467,  ..., -0.0742, -0.0426,  0.0469],\n",
      "        [ 0.0370,  0.0657, -0.0095,  ..., -0.0056, -0.0761, -0.0603]],\n",
      "       requires_grad=True)\n",
      "fc2.bias\n",
      "Parameter containing:\n",
      "tensor([-0.0241, -0.0224,  0.0201,  0.0564, -0.0433,  0.0658,  0.0840,  0.0777,\n",
      "        -0.0444, -0.0024,  0.0248, -0.0880,  0.0304, -0.0251,  0.0557,  0.0674,\n",
      "         0.0191,  0.0237, -0.0693,  0.0826,  0.0777, -0.0249,  0.0913, -0.0086,\n",
      "         0.0399,  0.0016, -0.0539, -0.0436, -0.0593, -0.0136, -0.0825, -0.0303,\n",
      "        -0.0889, -0.0447, -0.0375,  0.0652, -0.0862, -0.0560, -0.0329,  0.0751,\n",
      "         0.0599, -0.0287, -0.0584, -0.0779,  0.0857,  0.0202,  0.0489,  0.0700,\n",
      "         0.0393, -0.0343, -0.0451,  0.0055,  0.0610,  0.0583, -0.0115, -0.0247,\n",
      "        -0.0468, -0.0408, -0.0847, -0.0163,  0.0456, -0.0477,  0.0205,  0.0415,\n",
      "        -0.0744,  0.0677, -0.0622, -0.0020, -0.0207,  0.0805,  0.0663,  0.0475,\n",
      "        -0.0885, -0.0044,  0.0735,  0.0402,  0.0084, -0.0474, -0.0021, -0.0178,\n",
      "        -0.0446, -0.0337,  0.0205, -0.0422], requires_grad=True)\n",
      "fc3.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0655, -0.0513,  0.0073, -0.0171, -0.0565,  0.0071,  0.0487, -0.0763,\n",
      "         -0.0302, -0.0696, -0.0595,  0.0246, -0.0037, -0.0191, -0.0803, -0.0840,\n",
      "          0.1013, -0.0372,  0.0454, -0.0565, -0.0612,  0.0880,  0.0774, -0.0835,\n",
      "          0.0915,  0.0056, -0.0820,  0.1067, -0.0653,  0.0389,  0.0846,  0.0288,\n",
      "         -0.0262,  0.0882, -0.0110, -0.0926,  0.0900,  0.0021,  0.0566, -0.0391,\n",
      "         -0.0184, -0.0026, -0.0334,  0.0568,  0.0568,  0.0381,  0.0150, -0.0185,\n",
      "          0.0514,  0.0012,  0.1011,  0.0498, -0.0467,  0.0336, -0.0786, -0.0591,\n",
      "          0.0086,  0.0327,  0.0191, -0.0498,  0.0269, -0.0103,  0.0819, -0.0242,\n",
      "          0.0807,  0.0141,  0.0632,  0.0920, -0.0449, -0.0134, -0.0510,  0.0479,\n",
      "         -0.0599,  0.0005, -0.0897, -0.0222,  0.0507,  0.0379, -0.0196,  0.0832,\n",
      "          0.0011, -0.0283,  0.0873, -0.0033],\n",
      "        [-0.0172, -0.0795,  0.0109,  0.0060,  0.0157,  0.0703, -0.0914,  0.1032,\n",
      "          0.0537, -0.0892, -0.1086,  0.0501,  0.0232, -0.0996,  0.1082, -0.0897,\n",
      "          0.0369, -0.0700, -0.0138, -0.0110, -0.0472, -0.0266,  0.0757,  0.0139,\n",
      "         -0.0263, -0.0780,  0.0673, -0.0612,  0.0945, -0.0621,  0.0833, -0.0890,\n",
      "          0.0778, -0.0469, -0.0805, -0.0213, -0.0332, -0.0681, -0.0802,  0.0771,\n",
      "          0.0673, -0.0698, -0.0311, -0.0289,  0.0351, -0.0556, -0.0209, -0.0281,\n",
      "         -0.0022, -0.0336, -0.0227, -0.0359, -0.0364,  0.0817, -0.0446, -0.0975,\n",
      "         -0.0893,  0.0667, -0.0220, -0.0067,  0.0839, -0.0770,  0.0161, -0.0664,\n",
      "          0.0900, -0.0250, -0.0044,  0.0961,  0.0091,  0.0076,  0.0674, -0.0336,\n",
      "         -0.0534, -0.0699,  0.0435, -0.0253,  0.0917, -0.1034,  0.0626, -0.0059,\n",
      "         -0.0316, -0.1009,  0.0516,  0.0043],\n",
      "        [ 0.0242,  0.0099, -0.0551, -0.0226,  0.0843, -0.0437,  0.0627,  0.0581,\n",
      "         -0.1018, -0.0358,  0.0696,  0.0152,  0.0843, -0.0107, -0.0142, -0.0371,\n",
      "          0.1036,  0.0204,  0.0871,  0.0937,  0.0589,  0.0376, -0.0210,  0.1081,\n",
      "         -0.0191,  0.0896,  0.0925,  0.1009, -0.0675, -0.0217,  0.0621,  0.0323,\n",
      "         -0.0318,  0.0670, -0.0778,  0.0675, -0.0272,  0.1042, -0.0557, -0.0778,\n",
      "          0.0462,  0.0378,  0.0992,  0.0796, -0.0996, -0.1087, -0.0620,  0.0589,\n",
      "         -0.0932,  0.0819,  0.0618,  0.0726, -0.0829,  0.0253,  0.0572, -0.0416,\n",
      "          0.0343,  0.0920, -0.0315,  0.0464,  0.0578,  0.0963,  0.0045, -0.0459,\n",
      "          0.0072, -0.0087, -0.0477,  0.0247, -0.0216,  0.0871,  0.0488,  0.1014,\n",
      "         -0.0686,  0.0036, -0.0306,  0.0465, -0.1036,  0.0188,  0.0802,  0.0620,\n",
      "          0.0053, -0.0585, -0.0115,  0.0296],\n",
      "        [ 0.0284,  0.0469,  0.0135,  0.0321,  0.0382, -0.0738, -0.0785, -0.0918,\n",
      "         -0.0347, -0.0905,  0.0766,  0.0591,  0.0986, -0.0249,  0.0016, -0.0195,\n",
      "         -0.0252, -0.0094,  0.0806, -0.0116, -0.0471,  0.0351,  0.0436, -0.1006,\n",
      "         -0.0178, -0.0847,  0.0399,  0.0492, -0.0869,  0.1012,  0.0128, -0.0267,\n",
      "         -0.0917,  0.0472,  0.0453, -0.0228,  0.0282, -0.0872, -0.1073, -0.0805,\n",
      "          0.0807,  0.0738,  0.0925,  0.0457,  0.0276,  0.0896,  0.0907, -0.0250,\n",
      "         -0.0118,  0.0035, -0.0602,  0.1055, -0.0832, -0.0724, -0.0146, -0.0645,\n",
      "         -0.0116, -0.0741,  0.0772,  0.0943,  0.0663, -0.0418, -0.0962, -0.0648,\n",
      "         -0.0776,  0.0245,  0.0373, -0.0206,  0.0569,  0.0895,  0.0617, -0.0313,\n",
      "         -0.0551,  0.1034, -0.0848,  0.0228, -0.0946,  0.1015,  0.0548, -0.0750,\n",
      "          0.0141,  0.0894,  0.0336, -0.0781],\n",
      "        [-0.1028, -0.0284,  0.0499, -0.0925,  0.0762,  0.0094, -0.0867,  0.0672,\n",
      "          0.0664, -0.0386,  0.0600,  0.0625,  0.1030, -0.0259,  0.0739,  0.0473,\n",
      "         -0.0474,  0.0514, -0.0631,  0.0747, -0.0166, -0.0422,  0.0057,  0.0584,\n",
      "          0.0034,  0.0272,  0.0328, -0.0296, -0.0087,  0.0303, -0.1070,  0.0470,\n",
      "         -0.0638, -0.0566,  0.0371,  0.0255,  0.0970, -0.0400, -0.0266, -0.0024,\n",
      "         -0.0639, -0.0674,  0.0120, -0.1014,  0.0134,  0.0751, -0.0432,  0.0047,\n",
      "         -0.0730,  0.0686,  0.0081,  0.0381,  0.0496,  0.0506, -0.0725,  0.0971,\n",
      "          0.1052,  0.0797,  0.0981,  0.0616, -0.0596,  0.0014, -0.0866, -0.0495,\n",
      "          0.0554, -0.0870, -0.0912, -0.0250, -0.0899,  0.0055, -0.0476, -0.0201,\n",
      "          0.0132, -0.1001, -0.0056, -0.0575, -0.0107,  0.0770,  0.0917,  0.0018,\n",
      "          0.0999,  0.0077,  0.0201,  0.0944],\n",
      "        [ 0.0898,  0.0786, -0.0931,  0.0065, -0.0262, -0.0487, -0.0739,  0.0169,\n",
      "         -0.0607, -0.0199, -0.0026, -0.0470,  0.0768,  0.0049, -0.0626, -0.0754,\n",
      "         -0.1047, -0.0117,  0.0472, -0.0908, -0.0390,  0.1003, -0.0662,  0.0927,\n",
      "         -0.0713, -0.0166, -0.0222, -0.0436, -0.0102,  0.0729, -0.0689, -0.0804,\n",
      "          0.0569, -0.0267, -0.0384,  0.0532,  0.0680, -0.0368, -0.0341,  0.0412,\n",
      "         -0.0478,  0.0847,  0.0351, -0.0980,  0.0262,  0.0708,  0.0406,  0.0062,\n",
      "          0.0007, -0.0728,  0.0335,  0.0467, -0.0391, -0.0096,  0.0989,  0.0478,\n",
      "         -0.0393, -0.0320, -0.0191, -0.0469, -0.0419, -0.0823,  0.0547, -0.0911,\n",
      "          0.0437,  0.0694,  0.0087,  0.0805,  0.0377, -0.0211, -0.0400, -0.0451,\n",
      "         -0.0294,  0.0203, -0.1002,  0.0100,  0.0923,  0.0512, -0.0317,  0.0104,\n",
      "         -0.0944, -0.0234,  0.0925, -0.0515],\n",
      "        [ 0.0827,  0.0746, -0.0834,  0.0814, -0.0374,  0.0846,  0.0751,  0.1029,\n",
      "          0.0928, -0.0555, -0.0725, -0.0836, -0.0352,  0.0289,  0.0061, -0.0867,\n",
      "         -0.0265, -0.0820, -0.0430,  0.0877,  0.0826,  0.0989,  0.0740,  0.0397,\n",
      "          0.0444,  0.0947, -0.0999,  0.0298,  0.0504, -0.0651,  0.0459,  0.0310,\n",
      "          0.0890,  0.0473,  0.0866,  0.0324, -0.0089, -0.0524,  0.0830,  0.0804,\n",
      "         -0.0507, -0.0374, -0.0170, -0.0880, -0.0569,  0.0884, -0.1043, -0.0231,\n",
      "          0.0099,  0.0085, -0.0485,  0.0264, -0.0761, -0.0053, -0.0019, -0.0759,\n",
      "          0.0945,  0.0929, -0.0284,  0.0586, -0.0705, -0.0304,  0.0807,  0.0648,\n",
      "          0.0949,  0.1039, -0.0975, -0.0486,  0.0190, -0.0083,  0.0063,  0.0612,\n",
      "          0.0735, -0.0468,  0.0704,  0.0687, -0.0436, -0.0480, -0.0172, -0.0529,\n",
      "          0.0276, -0.1027,  0.0346, -0.0924],\n",
      "        [ 0.0169,  0.0515,  0.0100,  0.0557,  0.0795, -0.0647, -0.0048, -0.0522,\n",
      "          0.0052,  0.1010,  0.0559, -0.0980,  0.0231, -0.0308, -0.0473, -0.0517,\n",
      "         -0.0646,  0.0028, -0.0410, -0.1073, -0.0653,  0.0713, -0.0468,  0.1024,\n",
      "          0.0715,  0.0245,  0.1035,  0.0344,  0.0732,  0.0246, -0.0641,  0.0165,\n",
      "          0.0413,  0.0438, -0.0874, -0.0807, -0.0205,  0.1018, -0.0310, -0.0666,\n",
      "          0.0720, -0.0132, -0.0855,  0.0115, -0.0986,  0.0271,  0.0580, -0.0194,\n",
      "          0.0966,  0.0344, -0.0127, -0.0835, -0.0133,  0.0133,  0.0165, -0.0914,\n",
      "          0.0083, -0.0200,  0.0083,  0.0660,  0.1074,  0.0101,  0.0842, -0.0592,\n",
      "          0.0442, -0.0245,  0.1074,  0.0449,  0.0315, -0.0451,  0.0183,  0.0501,\n",
      "         -0.1061,  0.0476,  0.0273, -0.0650, -0.0738, -0.0857, -0.0639, -0.0814,\n",
      "         -0.0486, -0.0002, -0.1034, -0.0519],\n",
      "        [-0.0930, -0.1066, -0.0732, -0.1057, -0.0904,  0.0865,  0.0842, -0.0641,\n",
      "         -0.0574, -0.0254,  0.0086, -0.0041,  0.0483, -0.0337,  0.0424, -0.0753,\n",
      "          0.0692,  0.0810, -0.0272, -0.0419, -0.0011, -0.0108,  0.0828,  0.0299,\n",
      "         -0.1023,  0.0996, -0.1082,  0.0057,  0.0146, -0.0039, -0.0241,  0.0439,\n",
      "          0.0713, -0.0896,  0.0626,  0.0855,  0.0773, -0.0082,  0.0903,  0.0250,\n",
      "         -0.0876,  0.0887, -0.0844,  0.0401,  0.0376, -0.0497, -0.0106,  0.0836,\n",
      "         -0.0666, -0.1007,  0.0638,  0.0208,  0.0015,  0.0997, -0.0319, -0.0544,\n",
      "          0.0814, -0.0988, -0.0150,  0.0301, -0.0890, -0.0134,  0.0476,  0.0109,\n",
      "          0.0197,  0.0993,  0.0384, -0.0904,  0.0272, -0.0787, -0.0515, -0.0984,\n",
      "          0.0961,  0.0679,  0.0814, -0.0562, -0.0890,  0.0989,  0.1015,  0.0964,\n",
      "          0.0583, -0.0141, -0.0406, -0.0051],\n",
      "        [ 0.0428,  0.0468,  0.0191,  0.0153,  0.0380, -0.0786, -0.0739,  0.0189,\n",
      "         -0.0700, -0.0665,  0.1036,  0.0170, -0.0569, -0.0408,  0.0026, -0.0533,\n",
      "         -0.1064, -0.0829,  0.0175, -0.0141, -0.0472, -0.0719,  0.1028,  0.0320,\n",
      "         -0.0963, -0.0841, -0.0433,  0.0509,  0.0804,  0.0514, -0.0780, -0.0381,\n",
      "         -0.1083, -0.0943, -0.0460, -0.0858,  0.1040, -0.0651,  0.0213,  0.0644,\n",
      "          0.1079, -0.1049,  0.0560,  0.0192,  0.0953,  0.0750,  0.0211, -0.0613,\n",
      "         -0.0818, -0.0132, -0.0091, -0.0516,  0.0585, -0.0115,  0.0592, -0.0554,\n",
      "          0.0569, -0.0999, -0.0460, -0.0713, -0.0991, -0.0723,  0.0192, -0.0057,\n",
      "         -0.1046, -0.1021, -0.0892, -0.0479, -0.1049,  0.0287,  0.0077, -0.0039,\n",
      "          0.0879, -0.0892,  0.0461, -0.0450,  0.0426, -0.0271,  0.0481,  0.0761,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -0.0779, -0.0652,  0.0259,  0.0619]], requires_grad=True)\n",
      "fc3.bias\n",
      "Parameter containing:\n",
      "tensor([ 0.0735,  0.0597, -0.0657, -0.0325, -0.1080,  0.0378,  0.0782,  0.0246,\n",
      "        -0.0205, -0.0889], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for n, p in list(net.named_parameters()):\n",
    "    print(n)\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conv1.weight', Parameter containing:\n",
       "  tensor([[[[-1.3551e-02,  7.1723e-02,  1.3095e-01, -1.7946e-01, -1.9144e-01],\n",
       "            [-6.3771e-02,  5.0846e-02, -1.6471e-01, -1.5248e-01, -1.9750e-01],\n",
       "            [ 1.7952e-01,  9.8860e-03, -4.5322e-02, -7.7297e-03,  5.0834e-02],\n",
       "            [ 1.4284e-01, -6.8309e-02, -1.1847e-01,  1.3641e-01,  1.9590e-01],\n",
       "            [ 1.7032e-01,  6.5213e-02,  8.5182e-02,  5.6357e-02,  1.7980e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[ 7.1066e-02, -1.3164e-01, -1.0162e-01,  1.3573e-01,  5.5445e-02],\n",
       "            [-6.8366e-02, -1.5092e-01, -2.4752e-03, -3.5418e-03,  1.6175e-01],\n",
       "            [ 4.9975e-02, -1.0374e-01,  1.4506e-01, -9.8533e-02,  1.1970e-01],\n",
       "            [-1.6559e-01,  1.6889e-01, -5.4293e-02,  9.1411e-02, -1.4294e-01],\n",
       "            [-1.3175e-01, -8.1450e-02, -1.3395e-02,  4.7471e-02,  1.0807e-01]]],\n",
       "  \n",
       "  \n",
       "          [[[-8.5364e-02, -8.2596e-02,  5.4527e-02, -1.6190e-01,  1.3557e-01],\n",
       "            [-1.2136e-04, -1.3412e-01, -1.2526e-01, -7.2968e-02,  1.0480e-01],\n",
       "            [ 4.9474e-03,  1.9435e-02,  1.5984e-01,  1.4222e-01,  1.5758e-01],\n",
       "            [-2.2595e-02, -1.2741e-01,  1.4262e-01,  1.2594e-01, -6.9949e-02],\n",
       "            [ 7.4408e-02,  1.0627e-01,  1.7866e-01, -1.5469e-01, -7.4779e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[ 4.7682e-02,  2.1636e-02,  1.7551e-01,  1.4654e-01,  5.6046e-02],\n",
       "            [ 7.7519e-02,  1.6515e-02,  1.6059e-01,  1.4803e-01,  1.8672e-01],\n",
       "            [-1.6514e-01,  1.8463e-01, -7.4569e-02, -9.4933e-02,  1.0967e-01],\n",
       "            [-1.7592e-01, -1.0182e-01, -5.1844e-02, -7.6537e-02, -1.7458e-02],\n",
       "            [-9.7663e-02, -1.4829e-01, -7.1746e-02, -9.3615e-02,  1.5898e-01]]],\n",
       "  \n",
       "  \n",
       "          [[[-1.5539e-01, -1.6196e-01, -7.6788e-02, -1.8198e-01, -6.7547e-02],\n",
       "            [-1.7761e-02,  1.4172e-01,  3.0540e-02, -1.1003e-01, -4.1229e-02],\n",
       "            [ 1.1739e-01, -1.7746e-01,  5.5547e-02, -9.2608e-02,  1.1018e-01],\n",
       "            [ 1.3827e-01,  6.6980e-02,  7.4876e-02,  1.7342e-01,  1.9389e-01],\n",
       "            [ 1.7264e-01, -1.5125e-01, -1.0727e-01, -9.0587e-02,  3.5627e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[-1.8747e-01,  1.4388e-01, -4.8587e-04, -1.6511e-02,  1.2899e-01],\n",
       "            [ 1.4788e-02,  1.7315e-01,  6.4228e-02,  9.2043e-02, -8.7797e-02],\n",
       "            [ 1.4056e-01, -1.1609e-01,  1.3362e-01,  1.8605e-01, -4.2717e-02],\n",
       "            [-3.6386e-02, -1.5192e-01, -1.7254e-01,  1.5087e-01,  1.4686e-02],\n",
       "            [ 1.5140e-01, -1.1511e-01,  3.2004e-02, -7.9017e-02,  5.8165e-02]]]],\n",
       "         requires_grad=True)), ('conv1.bias', Parameter containing:\n",
       "  tensor([ 0.0020, -0.0019, -0.1359,  0.0299, -0.1280, -0.1242],\n",
       "         requires_grad=True)), ('conv2.weight', Parameter containing:\n",
       "  tensor([[[[ 6.2388e-02, -5.7742e-02, -8.1258e-02,  4.3874e-02, -5.4451e-02],\n",
       "            [ 2.4633e-02,  1.3621e-02, -3.8918e-02,  7.4136e-03, -7.0569e-04],\n",
       "            [ 4.7172e-02, -7.7290e-02,  6.6885e-02, -8.1057e-02,  3.7612e-02],\n",
       "            [-7.0277e-02, -7.4744e-02, -5.8966e-02, -1.5464e-02, -5.3663e-02],\n",
       "            [ 5.3934e-02,  1.2848e-03,  1.7805e-02,  8.0592e-02,  6.5491e-02]],\n",
       "  \n",
       "           [[ 5.2751e-03,  5.2791e-03, -3.5561e-03,  4.2472e-02,  6.3408e-02],\n",
       "            [ 7.2715e-02, -1.2413e-02, -2.8806e-02,  7.9662e-02, -7.1534e-02],\n",
       "            [ 3.6635e-03,  3.4118e-02, -4.6710e-02, -1.6963e-02, -5.5685e-02],\n",
       "            [ 5.1969e-02, -4.1458e-02,  4.8944e-02,  2.9057e-02,  7.8767e-02],\n",
       "            [ 5.8731e-02,  1.5743e-02, -4.7967e-02,  3.4909e-02, -4.0660e-02]],\n",
       "  \n",
       "           [[ 1.9414e-03,  3.7159e-02,  3.2136e-02, -5.7980e-02, -7.0120e-02],\n",
       "            [ 4.8349e-02, -7.8386e-02, -6.9015e-02, -2.3768e-02, -6.0622e-02],\n",
       "            [ 1.9612e-02,  7.6866e-02, -1.6298e-02, -7.2721e-02,  4.4023e-02],\n",
       "            [ 2.5518e-03, -4.2705e-02, -3.1113e-02,  5.0266e-02,  2.6984e-02],\n",
       "            [ 2.5590e-02, -7.6565e-02, -3.4492e-02,  2.2703e-02,  2.1547e-02]],\n",
       "  \n",
       "           [[-5.2363e-05, -2.7185e-02, -1.6272e-02, -6.1310e-02, -3.4509e-02],\n",
       "            [ 6.1927e-04, -3.0052e-02,  2.5932e-02, -5.0579e-02,  2.1714e-02],\n",
       "            [-5.7533e-02, -3.5440e-02,  7.3799e-02, -6.9738e-02, -5.4493e-03],\n",
       "            [-3.3244e-02,  3.9866e-02, -6.5730e-02,  4.0080e-03, -6.3943e-02],\n",
       "            [-3.8805e-02,  6.7640e-02,  3.1853e-02,  1.1752e-03,  4.5375e-02]],\n",
       "  \n",
       "           [[-2.0894e-02,  5.4517e-02,  8.1621e-02,  7.0975e-03,  4.9515e-02],\n",
       "            [-3.3716e-02, -3.2237e-02,  5.6568e-02, -4.1122e-02,  2.0643e-02],\n",
       "            [ 1.2271e-02, -1.6613e-02, -4.6177e-03, -4.1395e-04,  2.5261e-02],\n",
       "            [-5.5114e-02, -2.9068e-02,  3.0954e-02, -1.5218e-02,  1.4479e-02],\n",
       "            [-6.6128e-02,  7.3331e-02,  8.1203e-02,  1.9015e-02,  6.9719e-02]],\n",
       "  \n",
       "           [[ 5.9821e-02,  5.9611e-02, -5.8235e-02, -4.1666e-02,  1.6417e-02],\n",
       "            [-7.5853e-02,  4.2406e-02, -3.1872e-02, -2.0016e-02,  6.9476e-02],\n",
       "            [ 2.6793e-02, -5.9271e-02, -1.1908e-02,  3.9124e-02,  4.8907e-02],\n",
       "            [ 2.0887e-02, -5.3211e-02,  7.8924e-02, -6.1370e-02,  3.7245e-02],\n",
       "            [ 4.6207e-02,  6.7378e-02, -3.7825e-02, -4.7611e-02, -2.4376e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[ 2.8868e-02,  5.1925e-02,  2.7584e-02,  4.5272e-02,  7.6485e-03],\n",
       "            [-6.6399e-02,  8.1284e-02,  1.2940e-02, -8.8542e-03,  5.0375e-02],\n",
       "            [ 2.0407e-02, -4.3311e-02,  1.2219e-02,  5.7694e-02,  5.9360e-02],\n",
       "            [-2.3577e-02,  1.9204e-02, -3.2978e-02,  1.9627e-03, -4.6947e-02],\n",
       "            [-5.2870e-02,  4.5329e-02, -1.0780e-02, -3.7516e-03,  2.4789e-02]],\n",
       "  \n",
       "           [[-4.8989e-02, -1.6979e-02,  7.4063e-02, -4.4738e-02, -4.1345e-02],\n",
       "            [ 2.4057e-02,  7.8927e-02, -7.5880e-02,  1.0396e-02, -7.0526e-02],\n",
       "            [ 5.6404e-03, -6.4327e-02,  3.2865e-02, -4.9885e-02,  3.6337e-02],\n",
       "            [ 3.7183e-02,  7.0283e-03, -5.7778e-02, -5.8387e-02, -4.7943e-02],\n",
       "            [ 6.3855e-02, -3.1289e-03,  3.8303e-03,  7.0262e-02,  6.2704e-03]],\n",
       "  \n",
       "           [[-6.4403e-02,  3.2793e-02, -7.8985e-02, -1.8421e-02,  7.2924e-03],\n",
       "            [ 6.1709e-02, -5.8900e-02,  1.8790e-02, -6.1457e-02, -7.7264e-02],\n",
       "            [-3.4879e-02,  7.0751e-02, -4.7332e-03,  6.8165e-03,  5.5482e-02],\n",
       "            [-7.7527e-02,  4.2268e-02,  5.6691e-02,  1.0009e-02, -4.9628e-02],\n",
       "            [ 4.4891e-02, -5.1613e-02,  4.8766e-02,  5.1724e-02, -1.5341e-03]],\n",
       "  \n",
       "           [[ 4.4373e-02,  7.1716e-02,  2.2899e-02,  4.2696e-02,  1.0046e-02],\n",
       "            [-7.6665e-02, -4.5002e-03,  4.5349e-02,  1.2300e-02, -2.2023e-02],\n",
       "            [-6.8020e-02, -5.0667e-02,  2.6992e-02,  6.5590e-02,  4.6417e-02],\n",
       "            [-1.7409e-02,  4.8760e-02, -6.1562e-02, -6.5563e-02,  3.6771e-02],\n",
       "            [ 7.4924e-02, -6.0831e-02,  2.2871e-02,  1.4960e-02,  1.6196e-03]],\n",
       "  \n",
       "           [[-5.5987e-03,  1.5725e-02,  4.5778e-02,  2.6192e-02,  4.9862e-04],\n",
       "            [ 5.8044e-02, -7.8546e-02,  5.0620e-02,  3.9225e-02, -4.4774e-02],\n",
       "            [ 7.9432e-02,  3.0863e-02,  3.9329e-03, -5.6261e-02, -1.4348e-02],\n",
       "            [-1.0625e-02, -4.2326e-02,  2.8160e-02, -1.1206e-02, -7.8877e-02],\n",
       "            [-6.9844e-02,  6.8339e-02,  5.7921e-02, -7.7220e-02, -4.0788e-02]],\n",
       "  \n",
       "           [[-2.2388e-02, -7.1533e-02,  4.5186e-02, -7.8773e-02, -5.0850e-02],\n",
       "            [-3.9795e-02,  2.1884e-02,  2.7676e-02, -6.0629e-02,  6.2120e-02],\n",
       "            [-5.5790e-02, -6.0689e-02, -7.6685e-02,  5.4283e-02, -2.0017e-04],\n",
       "            [-7.7355e-02, -3.7417e-03,  1.9103e-02, -5.9867e-02,  1.3416e-03],\n",
       "            [-5.7789e-02, -7.6180e-02, -3.3640e-02, -3.6040e-02, -4.9723e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[-1.1371e-02,  6.7236e-02,  8.8133e-04,  6.6290e-02, -4.4047e-02],\n",
       "            [ 5.7861e-02,  4.8886e-02,  4.1892e-02, -1.6675e-02,  7.9339e-02],\n",
       "            [ 7.2640e-02,  7.4117e-02,  1.5753e-02, -1.8924e-02, -1.4422e-02],\n",
       "            [-4.8292e-02, -2.8332e-02, -1.7221e-02,  3.3780e-03, -6.2761e-02],\n",
       "            [-4.9448e-02, -5.2144e-02, -5.5276e-02, -4.5957e-02,  2.0914e-02]],\n",
       "  \n",
       "           [[ 2.6746e-02,  2.4999e-02, -5.2206e-02,  1.4351e-02,  2.6128e-02],\n",
       "            [ 8.0601e-02, -5.0054e-02,  4.8877e-02, -9.6583e-03, -2.1569e-02],\n",
       "            [-3.3767e-03, -1.9156e-02, -1.4162e-02, -5.9559e-02,  7.3462e-02],\n",
       "            [-7.5718e-03,  1.7027e-02,  1.9158e-02,  3.8850e-02,  3.7180e-04],\n",
       "            [ 6.5527e-02, -4.2087e-02, -7.4974e-02, -1.6090e-02, -2.7393e-02]],\n",
       "  \n",
       "           [[-2.5039e-02,  3.9385e-02, -5.6949e-02, -4.7286e-02,  5.9374e-02],\n",
       "            [ 3.7656e-02,  3.4946e-02,  3.8991e-02,  5.9154e-02, -3.9949e-02],\n",
       "            [ 7.1003e-04,  6.0594e-02, -5.6692e-02,  1.7455e-02,  1.8726e-02],\n",
       "            [ 7.2458e-02, -4.3027e-02,  5.2253e-03, -5.5769e-03,  5.6157e-02],\n",
       "            [-5.1067e-02,  7.4239e-03,  2.0447e-02, -3.2877e-02,  7.8354e-02]],\n",
       "  \n",
       "           [[ 7.3107e-02,  3.4143e-02, -1.5369e-02,  3.8216e-02, -1.8360e-02],\n",
       "            [ 6.0878e-03,  6.4037e-02,  4.0642e-02, -4.3850e-02, -4.4012e-02],\n",
       "            [-8.0210e-02,  1.0018e-02, -2.0202e-02,  5.2501e-02,  7.1582e-02],\n",
       "            [-5.1250e-02,  5.6137e-02,  5.2230e-03, -5.2213e-02,  3.1062e-02],\n",
       "            [ 1.4594e-02,  3.4032e-02,  2.5432e-02, -3.3831e-02, -4.5172e-02]],\n",
       "  \n",
       "           [[-1.2760e-02,  1.4487e-02,  4.0919e-02,  1.0664e-02,  7.0154e-02],\n",
       "            [ 7.9861e-02, -5.7895e-03,  5.4381e-03, -4.7168e-02, -7.0959e-02],\n",
       "            [-7.5665e-02,  3.1124e-02,  5.3526e-02,  2.1929e-02,  5.1410e-02],\n",
       "            [ 1.3074e-02, -7.7517e-02, -4.2898e-02, -5.6892e-02,  4.5084e-02],\n",
       "            [-5.1147e-02, -2.5216e-02,  4.1506e-02,  5.2050e-02,  3.7649e-02]],\n",
       "  \n",
       "           [[ 3.4241e-02,  4.7032e-02,  2.7360e-02, -1.2098e-02,  4.7579e-02],\n",
       "            [ 6.5744e-02,  6.0748e-02,  5.3529e-03, -2.5687e-03,  4.9145e-02],\n",
       "            [-4.0882e-02,  5.0674e-02,  7.8843e-02, -4.3159e-02, -2.3994e-02],\n",
       "            [ 7.9138e-03, -3.5855e-02, -1.8193e-02, -5.6604e-02,  3.1877e-02],\n",
       "            [ 1.1459e-02,  6.0919e-02,  1.9484e-02, -7.4893e-02,  6.9911e-02]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[-4.0218e-02,  2.5560e-02, -1.0720e-02, -6.7009e-03, -2.3685e-02],\n",
       "            [ 7.1588e-02, -1.7095e-03,  3.4315e-02,  3.4113e-02,  7.5604e-02],\n",
       "            [-1.3453e-02, -1.2766e-02, -1.9406e-02,  7.8683e-02,  3.8064e-02],\n",
       "            [-3.7886e-02,  1.0154e-02, -7.2926e-02, -6.7341e-02,  7.4266e-03],\n",
       "            [-3.9049e-02, -5.7337e-02, -1.2963e-02,  3.3674e-02, -4.4310e-02]],\n",
       "  \n",
       "           [[ 5.5976e-05,  5.1189e-02,  7.1062e-02,  1.0339e-02,  5.5518e-02],\n",
       "            [ 7.1274e-02, -6.4442e-02,  1.1934e-02, -5.0876e-02, -1.2736e-02],\n",
       "            [ 1.3026e-02,  2.4105e-02,  7.4351e-02,  2.3290e-02,  4.9559e-02],\n",
       "            [ 7.3799e-02,  7.8030e-02,  7.3405e-02, -2.9665e-02,  5.5259e-02],\n",
       "            [-8.0227e-02, -5.5711e-02,  6.1129e-02, -5.4755e-02, -1.1816e-02]],\n",
       "  \n",
       "           [[-5.0499e-03, -6.5101e-02,  6.2491e-02,  6.6943e-02,  4.2320e-02],\n",
       "            [-2.4099e-02,  7.5993e-03,  3.1334e-02,  5.6737e-02,  4.7858e-03],\n",
       "            [ 8.1055e-02, -7.6626e-02,  6.3851e-02,  6.8584e-02, -3.4514e-02],\n",
       "            [ 7.6334e-02,  6.5564e-02,  2.5565e-02, -1.9234e-02, -4.8283e-02],\n",
       "            [ 8.0970e-02, -6.7799e-02,  4.6198e-02,  2.2371e-02,  5.3582e-02]],\n",
       "  \n",
       "           [[ 6.8644e-02, -4.3321e-02,  4.1193e-02, -1.7194e-02, -5.2951e-02],\n",
       "            [ 1.4715e-02, -2.4797e-02,  7.7257e-02,  9.4752e-03,  3.0012e-02],\n",
       "            [-7.5344e-02, -3.9113e-02,  7.9062e-03, -6.5991e-02,  2.9762e-02],\n",
       "            [-7.0060e-02, -7.5607e-02, -6.5714e-02,  1.6257e-02, -6.5840e-02],\n",
       "            [-4.6129e-02,  4.7077e-02, -2.2475e-04,  1.2058e-02,  7.8171e-02]],\n",
       "  \n",
       "           [[-4.6358e-02, -4.6426e-02, -7.1868e-02, -1.5023e-03, -8.7540e-03],\n",
       "            [ 7.2422e-02, -4.3064e-02,  2.0765e-02,  5.3919e-02, -1.2264e-02],\n",
       "            [-7.2785e-02, -4.4641e-02,  8.1247e-02,  6.2205e-02, -8.0370e-02],\n",
       "            [-3.8693e-02, -3.9175e-03, -7.9058e-02, -5.5737e-02,  7.7572e-02],\n",
       "            [-6.8030e-02, -1.5558e-02,  5.3432e-02,  5.9307e-02,  3.4125e-02]],\n",
       "  \n",
       "           [[ 7.7774e-02,  4.0886e-02,  1.7920e-04,  4.5547e-02,  6.1421e-02],\n",
       "            [ 3.7489e-02,  7.2195e-02,  7.4833e-02,  1.9301e-02,  1.9289e-02],\n",
       "            [-4.2094e-02, -5.1962e-03,  1.1599e-02,  1.1465e-02,  5.0151e-02],\n",
       "            [-7.7789e-02, -6.8736e-02,  3.2972e-02,  2.1256e-02,  4.3607e-02],\n",
       "            [ 5.0946e-02, -4.8660e-02, -1.1221e-02, -4.4236e-02,  1.4835e-03]]],\n",
       "  \n",
       "  \n",
       "          [[[-7.8765e-02, -3.9791e-02, -6.6161e-02,  3.9552e-02,  8.2665e-03],\n",
       "            [ 8.0635e-03,  6.3008e-02, -6.6789e-02,  9.7459e-03, -2.4606e-02],\n",
       "            [ 6.4617e-02,  5.9083e-02,  6.9399e-02,  5.1702e-02,  6.1535e-02],\n",
       "            [-4.0383e-02, -5.9128e-02,  3.2127e-02, -6.2940e-02,  7.8938e-02],\n",
       "            [-3.3663e-02,  5.9935e-02, -6.9492e-02, -7.7271e-02, -2.7223e-02]],\n",
       "  \n",
       "           [[ 9.2199e-03,  2.1181e-02, -6.0441e-02, -6.7574e-02, -3.5139e-02],\n",
       "            [ 6.2278e-02, -7.8074e-02,  7.2163e-02,  3.3903e-02,  4.1467e-02],\n",
       "            [-5.5489e-02,  2.1234e-02, -6.3362e-02,  5.8958e-02,  3.1462e-02],\n",
       "            [ 2.0472e-02, -3.1244e-02, -7.6267e-02, -3.8371e-02, -4.4264e-02],\n",
       "            [-7.9959e-02, -2.2301e-02, -6.5602e-02, -7.4358e-02, -4.3536e-02]],\n",
       "  \n",
       "           [[-7.5628e-02, -6.2658e-02,  7.2963e-02, -4.9658e-02, -7.3606e-03],\n",
       "            [ 5.0587e-02, -7.3952e-02,  6.3014e-02, -7.6996e-02,  5.5979e-02],\n",
       "            [-6.1459e-02,  4.2251e-02, -2.1445e-02,  1.1128e-02,  4.4446e-02],\n",
       "            [-4.4960e-03, -2.3184e-02, -6.9035e-02, -5.3340e-02,  6.0576e-02],\n",
       "            [ 2.8313e-02,  7.5711e-02,  7.0907e-02,  7.7681e-02,  3.9014e-02]],\n",
       "  \n",
       "           [[-7.6462e-02, -3.0594e-02,  7.8554e-02, -5.2791e-02,  7.1681e-02],\n",
       "            [-3.3717e-02,  1.7878e-02,  4.8156e-02,  4.0692e-02, -6.4831e-02],\n",
       "            [-3.5947e-02,  6.8471e-02,  7.8086e-02, -8.0733e-02, -7.8163e-03],\n",
       "            [ 3.7935e-02, -3.4607e-02, -1.4612e-02,  1.2097e-02,  2.0431e-02],\n",
       "            [-2.7819e-02,  5.4359e-02,  2.6460e-02, -4.0747e-02,  3.9084e-02]],\n",
       "  \n",
       "           [[ 2.5791e-02, -1.1047e-02,  3.2072e-02,  3.9812e-02,  2.9567e-02],\n",
       "            [-2.7046e-03, -4.3643e-02,  2.8720e-02,  6.3131e-02, -3.8804e-02],\n",
       "            [ 4.3588e-03, -2.8038e-02, -1.6792e-02,  6.1972e-02, -7.4074e-02],\n",
       "            [-4.6524e-02,  6.1631e-02, -1.5403e-02, -1.6055e-02,  1.3822e-04],\n",
       "            [-1.8322e-02,  3.2871e-03, -8.0853e-02,  4.5294e-02, -1.4215e-02]],\n",
       "  \n",
       "           [[ 2.5083e-02,  3.4168e-03,  4.4071e-02, -3.9614e-02,  3.1767e-03],\n",
       "            [ 1.1387e-02, -8.4593e-03, -1.7398e-02,  4.6395e-02,  5.4873e-02],\n",
       "            [ 4.9443e-02, -1.7829e-02, -7.4968e-02,  4.9983e-02,  6.5203e-02],\n",
       "            [ 1.5224e-02, -1.2134e-02, -9.0199e-03,  1.0726e-02, -7.1686e-02],\n",
       "            [-8.9038e-03, -5.6103e-02, -6.1042e-02,  2.6286e-02,  5.1318e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[-3.7627e-03, -6.1486e-03, -5.7750e-02,  1.7422e-02,  6.8028e-02],\n",
       "            [ 6.2087e-02, -4.0918e-02, -7.4711e-02, -2.4138e-02,  5.0443e-02],\n",
       "            [ 5.4089e-02, -5.2240e-03, -3.4530e-03,  6.6672e-02, -6.5896e-02],\n",
       "            [-2.7205e-02, -7.6944e-02,  7.1493e-02,  8.7818e-03,  4.1129e-02],\n",
       "            [-6.2804e-02,  6.3655e-02, -4.8569e-03, -4.4751e-02,  3.4504e-02]],\n",
       "  \n",
       "           [[ 5.9677e-02,  3.0008e-02,  4.0841e-02, -7.6502e-02, -5.3625e-03],\n",
       "            [ 1.3891e-02, -3.0525e-02, -2.9137e-02, -7.0508e-02,  5.1463e-02],\n",
       "            [ 7.6042e-02,  7.3930e-02,  2.8800e-02, -2.9757e-02, -1.0615e-02],\n",
       "            [ 6.7333e-02, -6.0740e-02, -1.7407e-02, -3.7994e-02,  1.1230e-02],\n",
       "            [-1.8024e-02,  2.8403e-02,  5.6754e-02, -8.7368e-03,  7.0222e-02]],\n",
       "  \n",
       "           [[ 2.5386e-02, -4.2424e-02,  5.6245e-02, -7.7386e-02, -2.4336e-02],\n",
       "            [-2.0159e-02,  2.2408e-02,  5.3645e-02,  3.9935e-03, -7.1652e-02],\n",
       "            [ 3.6478e-02, -6.9837e-02, -1.8387e-02, -1.8801e-02, -1.0053e-02],\n",
       "            [-3.2289e-02,  7.8720e-03, -5.2536e-03,  8.1032e-02,  7.3132e-02],\n",
       "            [ 1.9345e-02,  5.0137e-02,  3.1808e-02,  5.0663e-02, -2.4806e-02]],\n",
       "  \n",
       "           [[ 3.4760e-02, -4.0007e-02,  2.0400e-02, -8.8195e-03,  2.9926e-02],\n",
       "            [ 4.6972e-02, -3.0200e-02, -4.8686e-02, -5.3065e-02,  7.3031e-03],\n",
       "            [ 6.9076e-02, -1.2354e-02, -5.2642e-02,  1.7133e-02, -2.6328e-02],\n",
       "            [ 4.0799e-02, -4.1519e-02, -1.7737e-02,  1.6382e-02,  2.6203e-02],\n",
       "            [ 3.5796e-02,  3.5794e-02,  4.8140e-02, -8.1961e-04,  4.2458e-02]],\n",
       "  \n",
       "           [[-6.8238e-02, -6.9025e-02,  4.7482e-03,  7.3519e-02,  7.5495e-02],\n",
       "            [ 5.4546e-02,  6.5603e-02, -3.8515e-02,  7.4906e-02, -2.6983e-02],\n",
       "            [-2.5544e-02, -5.9059e-02,  2.4360e-02, -7.6712e-02,  1.2380e-02],\n",
       "            [-1.4863e-02,  2.0851e-02,  5.9859e-02,  6.7564e-03, -1.5764e-02],\n",
       "            [ 2.1338e-02,  4.7524e-02,  4.9039e-02,  2.1149e-02, -2.8334e-02]],\n",
       "  \n",
       "           [[ 6.9081e-02,  1.1502e-04,  3.5654e-02,  2.7331e-02,  5.6357e-02],\n",
       "            [-6.6598e-02,  7.2702e-02,  6.5332e-02, -4.7132e-02, -4.8414e-02],\n",
       "            [ 2.9385e-02,  3.3404e-02, -5.2773e-02,  7.2581e-02,  2.0353e-02],\n",
       "            [ 4.9098e-02,  4.6153e-02, -4.9346e-02, -2.7710e-02, -7.0648e-02],\n",
       "            [ 7.2180e-02, -6.5519e-02,  5.4893e-02,  7.7036e-02, -2.8238e-03]]]],\n",
       "         requires_grad=True)), ('conv2.bias', Parameter containing:\n",
       "  tensor([ 0.0326, -0.0050, -0.0077, -0.0480, -0.0015, -0.0358,  0.0006,  0.0553,\n",
       "          -0.0527,  0.0112, -0.0385,  0.0051, -0.0284,  0.0680, -0.0107, -0.0194],\n",
       "         requires_grad=True)), ('fc1.weight', Parameter containing:\n",
       "  tensor([[ 0.0262,  0.0459,  0.0487,  ...,  0.0470, -0.0373,  0.0406],\n",
       "          [ 0.0166,  0.0253,  0.0189,  ..., -0.0276, -0.0463,  0.0207],\n",
       "          [-0.0243, -0.0230, -0.0048,  ..., -0.0162,  0.0360, -0.0359],\n",
       "          ...,\n",
       "          [-0.0294, -0.0273,  0.0160,  ...,  0.0118,  0.0343,  0.0084],\n",
       "          [-0.0492,  0.0010, -0.0361,  ...,  0.0125, -0.0481,  0.0306],\n",
       "          [-0.0320, -0.0362,  0.0367,  ...,  0.0168,  0.0160, -0.0276]],\n",
       "         requires_grad=True)), ('fc1.bias', Parameter containing:\n",
       "  tensor([-1.1413e-03,  2.4427e-02,  3.8341e-02,  4.7606e-03,  4.5988e-02,\n",
       "           1.7020e-02, -2.7459e-02, -2.4151e-02, -1.5629e-02, -2.2665e-02,\n",
       "          -1.2155e-02, -8.9984e-04,  5.1179e-03, -4.7015e-02, -3.4684e-03,\n",
       "          -2.1990e-02,  3.0660e-02,  2.5520e-02,  4.8762e-02,  2.4282e-02,\n",
       "           1.7471e-02,  1.0241e-02,  2.5144e-02, -2.6074e-02,  4.0754e-02,\n",
       "          -1.7979e-02, -3.3758e-02,  4.3393e-03,  1.8655e-02,  1.7936e-02,\n",
       "           4.6449e-02, -3.6720e-02, -3.9897e-02, -2.2971e-02, -1.9432e-03,\n",
       "           3.0631e-02, -1.7195e-02,  4.9405e-02, -2.8371e-02, -1.0181e-02,\n",
       "           2.6708e-02, -1.7302e-02,  2.0149e-02,  9.9513e-03,  1.4374e-02,\n",
       "           1.7098e-02, -2.2804e-02,  2.1031e-02,  8.1550e-03, -1.5895e-02,\n",
       "           4.8552e-02, -2.9610e-02,  2.1583e-02, -1.5638e-02, -6.3568e-05,\n",
       "           1.8033e-02,  1.6830e-03,  4.8829e-02, -3.3067e-02,  3.9524e-02,\n",
       "          -3.0372e-02, -3.8770e-02,  2.3559e-02, -9.0977e-03, -2.3638e-02,\n",
       "          -1.2855e-02, -4.6206e-02, -2.9211e-02, -2.4439e-02,  2.7972e-02,\n",
       "          -1.4096e-02, -1.5841e-02, -4.6331e-02, -7.1072e-03,  3.5300e-02,\n",
       "           2.1060e-02, -1.7801e-03, -5.3392e-03,  3.3152e-02, -4.9898e-02,\n",
       "          -7.6211e-03, -4.0877e-02,  1.7668e-03,  6.7020e-03,  3.5685e-02,\n",
       "           2.7788e-02, -2.9722e-02,  1.5060e-02,  2.6168e-02,  2.8907e-02,\n",
       "           5.6434e-03, -7.6622e-03,  2.7209e-02,  4.9688e-02, -3.8915e-02,\n",
       "          -4.4182e-03, -1.5976e-02,  5.3218e-03, -2.7987e-02,  1.6514e-02,\n",
       "           4.6769e-02, -2.8087e-03, -4.3887e-02,  7.2881e-03,  2.1903e-03,\n",
       "          -1.8216e-02,  2.2027e-02, -2.4372e-02,  4.2839e-02, -4.3885e-02,\n",
       "          -2.3755e-04, -2.2289e-02,  2.9833e-02,  3.9198e-02,  2.6660e-02,\n",
       "          -3.8172e-02, -3.7314e-02,  3.6375e-02, -7.3730e-03,  8.2334e-03],\n",
       "         requires_grad=True)), ('fc2.weight', Parameter containing:\n",
       "  tensor([[ 0.0112,  0.0599,  0.0462,  ..., -0.0274, -0.0230, -0.0150],\n",
       "          [-0.0534, -0.0723, -0.0798,  ..., -0.0443,  0.0266, -0.0747],\n",
       "          [ 0.0723,  0.0227,  0.0169,  ...,  0.0330,  0.0220, -0.0400],\n",
       "          ...,\n",
       "          [-0.0041,  0.0033,  0.0883,  ..., -0.0275, -0.0527, -0.0767],\n",
       "          [ 0.0451, -0.0433,  0.0467,  ..., -0.0742, -0.0426,  0.0469],\n",
       "          [ 0.0370,  0.0657, -0.0095,  ..., -0.0056, -0.0761, -0.0603]],\n",
       "         requires_grad=True)), ('fc2.bias', Parameter containing:\n",
       "  tensor([-0.0241, -0.0224,  0.0201,  0.0564, -0.0433,  0.0658,  0.0840,  0.0777,\n",
       "          -0.0444, -0.0024,  0.0248, -0.0880,  0.0304, -0.0251,  0.0557,  0.0674,\n",
       "           0.0191,  0.0237, -0.0693,  0.0826,  0.0777, -0.0249,  0.0913, -0.0086,\n",
       "           0.0399,  0.0016, -0.0539, -0.0436, -0.0593, -0.0136, -0.0825, -0.0303,\n",
       "          -0.0889, -0.0447, -0.0375,  0.0652, -0.0862, -0.0560, -0.0329,  0.0751,\n",
       "           0.0599, -0.0287, -0.0584, -0.0779,  0.0857,  0.0202,  0.0489,  0.0700,\n",
       "           0.0393, -0.0343, -0.0451,  0.0055,  0.0610,  0.0583, -0.0115, -0.0247,\n",
       "          -0.0468, -0.0408, -0.0847, -0.0163,  0.0456, -0.0477,  0.0205,  0.0415,\n",
       "          -0.0744,  0.0677, -0.0622, -0.0020, -0.0207,  0.0805,  0.0663,  0.0475,\n",
       "          -0.0885, -0.0044,  0.0735,  0.0402,  0.0084, -0.0474, -0.0021, -0.0178,\n",
       "          -0.0446, -0.0337,  0.0205, -0.0422], requires_grad=True)), ('fc3.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0655, -0.0513,  0.0073, -0.0171, -0.0565,  0.0071,  0.0487, -0.0763,\n",
       "           -0.0302, -0.0696, -0.0595,  0.0246, -0.0037, -0.0191, -0.0803, -0.0840,\n",
       "            0.1013, -0.0372,  0.0454, -0.0565, -0.0612,  0.0880,  0.0774, -0.0835,\n",
       "            0.0915,  0.0056, -0.0820,  0.1067, -0.0653,  0.0389,  0.0846,  0.0288,\n",
       "           -0.0262,  0.0882, -0.0110, -0.0926,  0.0900,  0.0021,  0.0566, -0.0391,\n",
       "           -0.0184, -0.0026, -0.0334,  0.0568,  0.0568,  0.0381,  0.0150, -0.0185,\n",
       "            0.0514,  0.0012,  0.1011,  0.0498, -0.0467,  0.0336, -0.0786, -0.0591,\n",
       "            0.0086,  0.0327,  0.0191, -0.0498,  0.0269, -0.0103,  0.0819, -0.0242,\n",
       "            0.0807,  0.0141,  0.0632,  0.0920, -0.0449, -0.0134, -0.0510,  0.0479,\n",
       "           -0.0599,  0.0005, -0.0897, -0.0222,  0.0507,  0.0379, -0.0196,  0.0832,\n",
       "            0.0011, -0.0283,  0.0873, -0.0033],\n",
       "          [-0.0172, -0.0795,  0.0109,  0.0060,  0.0157,  0.0703, -0.0914,  0.1032,\n",
       "            0.0537, -0.0892, -0.1086,  0.0501,  0.0232, -0.0996,  0.1082, -0.0897,\n",
       "            0.0369, -0.0700, -0.0138, -0.0110, -0.0472, -0.0266,  0.0757,  0.0139,\n",
       "           -0.0263, -0.0780,  0.0673, -0.0612,  0.0945, -0.0621,  0.0833, -0.0890,\n",
       "            0.0778, -0.0469, -0.0805, -0.0213, -0.0332, -0.0681, -0.0802,  0.0771,\n",
       "            0.0673, -0.0698, -0.0311, -0.0289,  0.0351, -0.0556, -0.0209, -0.0281,\n",
       "           -0.0022, -0.0336, -0.0227, -0.0359, -0.0364,  0.0817, -0.0446, -0.0975,\n",
       "           -0.0893,  0.0667, -0.0220, -0.0067,  0.0839, -0.0770,  0.0161, -0.0664,\n",
       "            0.0900, -0.0250, -0.0044,  0.0961,  0.0091,  0.0076,  0.0674, -0.0336,\n",
       "           -0.0534, -0.0699,  0.0435, -0.0253,  0.0917, -0.1034,  0.0626, -0.0059,\n",
       "           -0.0316, -0.1009,  0.0516,  0.0043],\n",
       "          [ 0.0242,  0.0099, -0.0551, -0.0226,  0.0843, -0.0437,  0.0627,  0.0581,\n",
       "           -0.1018, -0.0358,  0.0696,  0.0152,  0.0843, -0.0107, -0.0142, -0.0371,\n",
       "            0.1036,  0.0204,  0.0871,  0.0937,  0.0589,  0.0376, -0.0210,  0.1081,\n",
       "           -0.0191,  0.0896,  0.0925,  0.1009, -0.0675, -0.0217,  0.0621,  0.0323,\n",
       "           -0.0318,  0.0670, -0.0778,  0.0675, -0.0272,  0.1042, -0.0557, -0.0778,\n",
       "            0.0462,  0.0378,  0.0992,  0.0796, -0.0996, -0.1087, -0.0620,  0.0589,\n",
       "           -0.0932,  0.0819,  0.0618,  0.0726, -0.0829,  0.0253,  0.0572, -0.0416,\n",
       "            0.0343,  0.0920, -0.0315,  0.0464,  0.0578,  0.0963,  0.0045, -0.0459,\n",
       "            0.0072, -0.0087, -0.0477,  0.0247, -0.0216,  0.0871,  0.0488,  0.1014,\n",
       "           -0.0686,  0.0036, -0.0306,  0.0465, -0.1036,  0.0188,  0.0802,  0.0620,\n",
       "            0.0053, -0.0585, -0.0115,  0.0296],\n",
       "          [ 0.0284,  0.0469,  0.0135,  0.0321,  0.0382, -0.0738, -0.0785, -0.0918,\n",
       "           -0.0347, -0.0905,  0.0766,  0.0591,  0.0986, -0.0249,  0.0016, -0.0195,\n",
       "           -0.0252, -0.0094,  0.0806, -0.0116, -0.0471,  0.0351,  0.0436, -0.1006,\n",
       "           -0.0178, -0.0847,  0.0399,  0.0492, -0.0869,  0.1012,  0.0128, -0.0267,\n",
       "           -0.0917,  0.0472,  0.0453, -0.0228,  0.0282, -0.0872, -0.1073, -0.0805,\n",
       "            0.0807,  0.0738,  0.0925,  0.0457,  0.0276,  0.0896,  0.0907, -0.0250,\n",
       "           -0.0118,  0.0035, -0.0602,  0.1055, -0.0832, -0.0724, -0.0146, -0.0645,\n",
       "           -0.0116, -0.0741,  0.0772,  0.0943,  0.0663, -0.0418, -0.0962, -0.0648,\n",
       "           -0.0776,  0.0245,  0.0373, -0.0206,  0.0569,  0.0895,  0.0617, -0.0313,\n",
       "           -0.0551,  0.1034, -0.0848,  0.0228, -0.0946,  0.1015,  0.0548, -0.0750,\n",
       "            0.0141,  0.0894,  0.0336, -0.0781],\n",
       "          [-0.1028, -0.0284,  0.0499, -0.0925,  0.0762,  0.0094, -0.0867,  0.0672,\n",
       "            0.0664, -0.0386,  0.0600,  0.0625,  0.1030, -0.0259,  0.0739,  0.0473,\n",
       "           -0.0474,  0.0514, -0.0631,  0.0747, -0.0166, -0.0422,  0.0057,  0.0584,\n",
       "            0.0034,  0.0272,  0.0328, -0.0296, -0.0087,  0.0303, -0.1070,  0.0470,\n",
       "           -0.0638, -0.0566,  0.0371,  0.0255,  0.0970, -0.0400, -0.0266, -0.0024,\n",
       "           -0.0639, -0.0674,  0.0120, -0.1014,  0.0134,  0.0751, -0.0432,  0.0047,\n",
       "           -0.0730,  0.0686,  0.0081,  0.0381,  0.0496,  0.0506, -0.0725,  0.0971,\n",
       "            0.1052,  0.0797,  0.0981,  0.0616, -0.0596,  0.0014, -0.0866, -0.0495,\n",
       "            0.0554, -0.0870, -0.0912, -0.0250, -0.0899,  0.0055, -0.0476, -0.0201,\n",
       "            0.0132, -0.1001, -0.0056, -0.0575, -0.0107,  0.0770,  0.0917,  0.0018,\n",
       "            0.0999,  0.0077,  0.0201,  0.0944],\n",
       "          [ 0.0898,  0.0786, -0.0931,  0.0065, -0.0262, -0.0487, -0.0739,  0.0169,\n",
       "           -0.0607, -0.0199, -0.0026, -0.0470,  0.0768,  0.0049, -0.0626, -0.0754,\n",
       "           -0.1047, -0.0117,  0.0472, -0.0908, -0.0390,  0.1003, -0.0662,  0.0927,\n",
       "           -0.0713, -0.0166, -0.0222, -0.0436, -0.0102,  0.0729, -0.0689, -0.0804,\n",
       "            0.0569, -0.0267, -0.0384,  0.0532,  0.0680, -0.0368, -0.0341,  0.0412,\n",
       "           -0.0478,  0.0847,  0.0351, -0.0980,  0.0262,  0.0708,  0.0406,  0.0062,\n",
       "            0.0007, -0.0728,  0.0335,  0.0467, -0.0391, -0.0096,  0.0989,  0.0478,\n",
       "           -0.0393, -0.0320, -0.0191, -0.0469, -0.0419, -0.0823,  0.0547, -0.0911,\n",
       "            0.0437,  0.0694,  0.0087,  0.0805,  0.0377, -0.0211, -0.0400, -0.0451,\n",
       "           -0.0294,  0.0203, -0.1002,  0.0100,  0.0923,  0.0512, -0.0317,  0.0104,\n",
       "           -0.0944, -0.0234,  0.0925, -0.0515],\n",
       "          [ 0.0827,  0.0746, -0.0834,  0.0814, -0.0374,  0.0846,  0.0751,  0.1029,\n",
       "            0.0928, -0.0555, -0.0725, -0.0836, -0.0352,  0.0289,  0.0061, -0.0867,\n",
       "           -0.0265, -0.0820, -0.0430,  0.0877,  0.0826,  0.0989,  0.0740,  0.0397,\n",
       "            0.0444,  0.0947, -0.0999,  0.0298,  0.0504, -0.0651,  0.0459,  0.0310,\n",
       "            0.0890,  0.0473,  0.0866,  0.0324, -0.0089, -0.0524,  0.0830,  0.0804,\n",
       "           -0.0507, -0.0374, -0.0170, -0.0880, -0.0569,  0.0884, -0.1043, -0.0231,\n",
       "            0.0099,  0.0085, -0.0485,  0.0264, -0.0761, -0.0053, -0.0019, -0.0759,\n",
       "            0.0945,  0.0929, -0.0284,  0.0586, -0.0705, -0.0304,  0.0807,  0.0648,\n",
       "            0.0949,  0.1039, -0.0975, -0.0486,  0.0190, -0.0083,  0.0063,  0.0612,\n",
       "            0.0735, -0.0468,  0.0704,  0.0687, -0.0436, -0.0480, -0.0172, -0.0529,\n",
       "            0.0276, -0.1027,  0.0346, -0.0924],\n",
       "          [ 0.0169,  0.0515,  0.0100,  0.0557,  0.0795, -0.0647, -0.0048, -0.0522,\n",
       "            0.0052,  0.1010,  0.0559, -0.0980,  0.0231, -0.0308, -0.0473, -0.0517,\n",
       "           -0.0646,  0.0028, -0.0410, -0.1073, -0.0653,  0.0713, -0.0468,  0.1024,\n",
       "            0.0715,  0.0245,  0.1035,  0.0344,  0.0732,  0.0246, -0.0641,  0.0165,\n",
       "            0.0413,  0.0438, -0.0874, -0.0807, -0.0205,  0.1018, -0.0310, -0.0666,\n",
       "            0.0720, -0.0132, -0.0855,  0.0115, -0.0986,  0.0271,  0.0580, -0.0194,\n",
       "            0.0966,  0.0344, -0.0127, -0.0835, -0.0133,  0.0133,  0.0165, -0.0914,\n",
       "            0.0083, -0.0200,  0.0083,  0.0660,  0.1074,  0.0101,  0.0842, -0.0592,\n",
       "            0.0442, -0.0245,  0.1074,  0.0449,  0.0315, -0.0451,  0.0183,  0.0501,\n",
       "           -0.1061,  0.0476,  0.0273, -0.0650, -0.0738, -0.0857, -0.0639, -0.0814,\n",
       "           -0.0486, -0.0002, -0.1034, -0.0519],\n",
       "          [-0.0930, -0.1066, -0.0732, -0.1057, -0.0904,  0.0865,  0.0842, -0.0641,\n",
       "           -0.0574, -0.0254,  0.0086, -0.0041,  0.0483, -0.0337,  0.0424, -0.0753,\n",
       "            0.0692,  0.0810, -0.0272, -0.0419, -0.0011, -0.0108,  0.0828,  0.0299,\n",
       "           -0.1023,  0.0996, -0.1082,  0.0057,  0.0146, -0.0039, -0.0241,  0.0439,\n",
       "            0.0713, -0.0896,  0.0626,  0.0855,  0.0773, -0.0082,  0.0903,  0.0250,\n",
       "           -0.0876,  0.0887, -0.0844,  0.0401,  0.0376, -0.0497, -0.0106,  0.0836,\n",
       "           -0.0666, -0.1007,  0.0638,  0.0208,  0.0015,  0.0997, -0.0319, -0.0544,\n",
       "            0.0814, -0.0988, -0.0150,  0.0301, -0.0890, -0.0134,  0.0476,  0.0109,\n",
       "            0.0197,  0.0993,  0.0384, -0.0904,  0.0272, -0.0787, -0.0515, -0.0984,\n",
       "            0.0961,  0.0679,  0.0814, -0.0562, -0.0890,  0.0989,  0.1015,  0.0964,\n",
       "            0.0583, -0.0141, -0.0406, -0.0051],\n",
       "          [ 0.0428,  0.0468,  0.0191,  0.0153,  0.0380, -0.0786, -0.0739,  0.0189,\n",
       "           -0.0700, -0.0665,  0.1036,  0.0170, -0.0569, -0.0408,  0.0026, -0.0533,\n",
       "           -0.1064, -0.0829,  0.0175, -0.0141, -0.0472, -0.0719,  0.1028,  0.0320,\n",
       "           -0.0963, -0.0841, -0.0433,  0.0509,  0.0804,  0.0514, -0.0780, -0.0381,\n",
       "           -0.1083, -0.0943, -0.0460, -0.0858,  0.1040, -0.0651,  0.0213,  0.0644,\n",
       "            0.1079, -0.1049,  0.0560,  0.0192,  0.0953,  0.0750,  0.0211, -0.0613,\n",
       "           -0.0818, -0.0132, -0.0091, -0.0516,  0.0585, -0.0115,  0.0592, -0.0554,\n",
       "            0.0569, -0.0999, -0.0460, -0.0713, -0.0991, -0.0723,  0.0192, -0.0057,\n",
       "           -0.1046, -0.1021, -0.0892, -0.0479, -0.1049,  0.0287,  0.0077, -0.0039,\n",
       "            0.0879, -0.0892,  0.0461, -0.0450,  0.0426, -0.0271,  0.0481,  0.0761,\n",
       "           -0.0779, -0.0652,  0.0259,  0.0619]], requires_grad=True)), ('fc3.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0735,  0.0597, -0.0657, -0.0325, -0.1080,  0.0378,  0.0782,  0.0246,\n",
       "          -0.0205, -0.0889], requires_grad=True))]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.train() 과 model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model 혹은 하나의 신경망을 생성하면 train()과 eval() attribute가 내장되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict() attribute는 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Net' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-212-9c594b503458>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Python\\anaconda36\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    537\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m--> 539\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Net' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "net.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Net' object has no attribute 'pred'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-213-3e2d3f9e95dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Python\\anaconda36\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    537\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m--> 539\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Net' object has no attribute 'pred'"
     ]
    }
   ],
   "source": [
    "net.pred()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## self.apply(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fn은 주로 Module 로 쓰지만 큰 의미는 없다고 한다\n",
    "#### 주로 model의 parameter 를 초기화할 때 이용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    print(m)\n",
    "    if type(m) == nn.Linear:\n",
    "        m.weight.data.fill_(1.0)\n",
    "        print(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2, out_features=2, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "Linear(in_features=2, out_features=2, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
    "net.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getattr(class 객체, '가져올 객체 이름')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 어떠한 신경망의 구성에서 가져오고 싶은 weight를 가져옴\n",
    "#### 단, 단계적으로 접근해야함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 현재 net에는 2가지의 레이어가 존재 각자 이름은 주어지지 않아 0 과 1로 되어 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2, out_features=2, bias=True)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(net, '0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하나이 레이어에는 weight와 bias가 기본적으로 내장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(getattr(net, '0'), 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.1563, -0.1596], requires_grad=True)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(getattr(net, '0'), 'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
